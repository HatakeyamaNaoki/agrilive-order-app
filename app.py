import streamlit as st
import streamlit_authenticator as stauth
import json
import pandas as pd
import io
import pytz
from config import get_openai_api_key, is_production, load_config, get_line_channel_access_token
from parser_infomart import parse_infomart
from parser_iporter import parse_iporter
from parser_mitsubishi import parse_mitsubishi
from parser_pdf import parse_pdf_handwritten
from prompt_line import get_line_order_prompt
from prompt_text import get_text_order_prompt
from docx import Document
import pdfplumber
from PIL import Image
import base64
import os
from datetime import datetime, timezone, timedelta
import requests
import sqlite3
from pathlib import Path
import tempfile
import filelock
from db import init_db, save_order_lines, list_batches, load_batch, get_batch_stats, DB_PATH, _conn

# ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ±ä¸€ï¼ˆAPP_DATA_DIRã‚’ä½¿ç”¨ï¼‰
from config import load_config
CONFIG = load_config()
DATA_DIR = Path(CONFIG.get("app_data_dir"))
DATA_DIR.mkdir(parents=True, exist_ok=True)

# LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ç®¡ç†ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
LINE_ORDERS_DIR = str(DATA_DIR / "line_orders")
if not os.path.exists(LINE_ORDERS_DIR):
    os.makedirs(LINE_ORDERS_DIR, exist_ok=True)

# ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ç®¡ç†ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
TEXT_ORDERS_DIR = str(DATA_DIR / "text_orders")
if not os.path.exists(TEXT_ORDERS_DIR):
    os.makedirs(TEXT_ORDERS_DIR, exist_ok=True)

# --- èªè¨¼æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ï¼ˆçµ±ä¸€ã•ã‚ŒãŸDATA_DIRã‚’ä½¿ç”¨ï¼‰ ---
CRED_PATH = DATA_DIR / "credentials.yml"
LOCK_PATH = CRED_PATH.with_suffix(".lock")

def _atomic_write_text(path: Path, text: str):
    """åŸå­çš„ã«ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã‚€"""
    try:
        print(f"åŸå­çš„æ›¸ãè¾¼ã¿é–‹å§‹: {path}")
        tmp = Path(tempfile.gettempdir()) / (path.name + ".tmp")
        print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«: {tmp}")
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(tmp, "w", encoding="utf-8") as f:
            f.write(text)
            f.flush()
            os.fsync(f.fileno())
        
        print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿å®Œäº†: {tmp}")
        os.replace(tmp, path)  # åŸå­çš„ç½®æ›
        print(f"åŸå­çš„ç½®æ›å®Œäº†: {path}")
        
    except Exception as e:
        print(f"åŸå­çš„æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if tmp.exists():
            try:
                tmp.unlink()
                print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {tmp}")
            except:
                pass
        raise

def _with_creds_lock(timeout=5):
    """èªè¨¼æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒƒã‚¯ã‚’å–å¾—"""
    try:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯å–å¾—é–‹å§‹: {LOCK_PATH}")
        # ãƒ­ãƒƒã‚¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        LOCK_PATH.parent.mkdir(parents=True, exist_ok=True)
        lock = filelock.FileLock(str(LOCK_PATH), timeout=timeout)
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯å–å¾—å®Œäº†: {LOCK_PATH}")
        return lock
    except Exception as e:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        raise

def get_file_lock(file_path, timeout=10):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ã‚’å–å¾—ã™ã‚‹ï¼ˆRenderç’°å¢ƒã§ã¯ç„¡åŠ¹åŒ–ï¼‰
    """
    import os
    
    # Renderç’°å¢ƒã§ã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ã‚’ç„¡åŠ¹åŒ–ï¼ˆRead-only file systemå¯¾ç­–ï¼‰
    if os.getenv('RENDER'):
        class DummyLock:
            def __enter__(self): return self
            def __exit__(self, *args): pass
        return DummyLock()
    
    try:
        import filelock
        lock_file = f"{file_path}.lock"
        return filelock.FileLock(lock_file, timeout=timeout)
    except ImportError:
        # filelockãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼ãƒ­ãƒƒã‚¯
        class DummyLock:
            def __enter__(self): return self
            def __exit__(self, *args): pass
        return DummyLock()

def save_line_order_data(line_account, sender_name, image_data, message_text=""):
    """
    LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    """
    try:
        # ç¾åœ¨ã®æ—¥æ™‚ã‚’å–å¾—
        jst = timezone(timedelta(hours=9))
        current_time = datetime.now(jst)
        order_date = current_time.strftime("%Y/%m/%d")
        # ãƒã‚¤ã‚¯ãƒ­ç§’ã¾ã§å«ã‚ã¦ä¸€æ„åŒ–ï¼ˆåŒä¸€ç§’å†…ã®è¤‡æ•°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾å¿œï¼‰
        timestamp = current_time.strftime("%Y%m%d_%H%M%S_%f")
        
        # æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        order_data = {
            "line_account": line_account,
            "sender_name": sender_name,
            "order_date": order_date,
            "timestamp": timestamp,
            "message_text": message_text,
            "image_filename": f"line_order_{timestamp}.png",
            "processed": False,
            "parsed_data": None  # è§£æçµæœã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ 
        }
        
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆåŒåãƒ•ã‚¡ã‚¤ãƒ«ã®è¡çªé˜²æ­¢ï¼‰
        image_path = os.path.join(LINE_ORDERS_DIR, order_data["image_filename"])
        base, ext = os.path.splitext(image_path)
        n = 1
        while os.path.exists(image_path):
            image_path = f"{base}_{n}{ext}"
            n += 1
        
        # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åã§order_dataã‚’æ›´æ–°
        order_data["image_filename"] = os.path.basename(image_path)
        
        with open(image_path, "wb") as f:
            f.write(image_data)
        
        # æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ä»˜ãï¼‰
        orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
        with get_file_lock(orders_file):
            orders = []
            if os.path.exists(orders_file):
                with open(orders_file, "r", encoding="utf-8") as f:
                    orders = json.load(f)
            
            orders.append(order_data)
            
            with open(orders_file, "w", encoding="utf-8") as f:
                json.dump(orders, f, ensure_ascii=False, indent=4)
        
        return True, "LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚"
    except Exception as e:
        return False, f"LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"

def save_parsed_line_order_data(timestamp, parsed_data):
    """
    LINEæ³¨æ–‡ã®è§£æçµæœã‚’ä¿å­˜
    """
    try:
        orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
        if not os.path.exists(orders_file):
            return False, "æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        
        with get_file_lock(orders_file):
            with open(orders_file, "r", encoding="utf-8") as f:
                orders = json.load(f)
            
            updated = False
            
            # â‘  ã¾ãš"æœªå‡¦ç†"ã®åŒtimestampã‚’å„ªå…ˆã—ã¦æ›´æ–°
            for order in orders:
                if order.get('timestamp') == timestamp and not order.get('processed', False):
                    order['parsed_data'] = parsed_data
                    order['processed'] = True
                    updated = True
                    break
            
            # â‘¡ å¿µã®ãŸã‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆæ—¢ã«å‡¦ç†æ¸ˆã¿ã°ã‹ã‚Šã§ã‚‚1ä»¶ã¯æ›´æ–°ï¼‰
            if not updated:
                for order in orders:
                    if order.get('timestamp') == timestamp:
                        order['parsed_data'] = parsed_data
                        order['processed'] = True
                        updated = True
                        break
            
            with open(orders_file, "w", encoding="utf-8") as f:
                json.dump(orders, f, ensure_ascii=False, indent=4)
        
        return True, "è§£æçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ"
    except Exception as e:
        return False, f"è§£æçµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"

def get_line_orders_for_user(email):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é–¢é€£ã™ã‚‹LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    """
    try:
        orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
        if not os.path.exists(orders_file):
            print(f"âŒ orders.jsonãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {orders_file}")
            return []
        
        with open(orders_file, "r", encoding="utf-8") as f:
            all_orders = json.load(f)
        
        print(f"ğŸ“Š å…¨æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿æ•°: {len(all_orders)}")
        print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {email}")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã§ç›´æ¥ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆæ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰
        user_orders = [order for order in all_orders if order.get("line_account") == email]
        print(f"ğŸ” ãƒ¦ãƒ¼ã‚¶ãƒ¼åã§ãƒ•ã‚£ãƒ«ã‚¿: {len(user_orders)}ä»¶")
        
        # ãƒ‡ãƒãƒƒã‚°: å…¨æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¡¨ç¤º
        for i, order in enumerate(all_orders):
            print(f"ğŸ“‹ æ³¨æ–‡{i+1}: line_account={order.get('line_account')}, sender_name={order.get('sender_name')}")
        
        return user_orders
    except Exception as e:
        print(f"LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def get_all_line_orders():
    """
    ã™ã¹ã¦ã®LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆç®¡ç†è€…ç”¨ï¼‰
    """
    try:
        orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
        if not os.path.exists(orders_file):
            return []
        
        with open(orders_file, "r", encoding="utf-8") as f:
            all_orders = json.load(f)
        
        return all_orders
    except Exception as e:
        print(f"å…¨LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []



def delete_processed_line_orders():
    """
    å‡¦ç†æ¸ˆã¿ã®LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    """
    try:
        orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
        if not os.path.exists(orders_file):
            return True, "å‰Šé™¤å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"
        
        with get_file_lock(orders_file):
            with open(orders_file, "r", encoding="utf-8") as f:
                all_orders = json.load(f)
            
            # å‡¦ç†æ¸ˆã¿ã®æ³¨æ–‡ã‚’å‰Šé™¤
            original_count = len(all_orders)
            remaining_orders = [order for order in all_orders if not order.get("processed", False)]
            deleted_count = original_count - len(remaining_orders)
            
            # å‰Šé™¤ã•ã‚ŒãŸæ³¨æ–‡ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤
            deleted_orders = [order for order in all_orders if order.get("processed", False)]
            for order in deleted_orders:
                image_path = os.path.join(LINE_ORDERS_DIR, order['image_filename'])
                if os.path.exists(image_path):
                    os.remove(image_path)
            
            # æ®‹ã‚Šã®æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            with open(orders_file, "w", encoding="utf-8") as f:
                json.dump(remaining_orders, f, ensure_ascii=False, indent=4)
        
        return True, f"{deleted_count}ä»¶ã®å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
    except Exception as e:
        return False, f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}"

def delete_line_order_by_timestamp(timestamp):
    """
    æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    """
    try:
        orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
        if not os.path.exists(orders_file):
            return False, "ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        
        with get_file_lock(orders_file):
            with open(orders_file, "r", encoding="utf-8") as f:
                all_orders = json.load(f)
            
            # æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®æ³¨æ–‡ã‚’å‰Šé™¤
            original_count = len(all_orders)
            remaining_orders = [order for order in all_orders if order['timestamp'] != timestamp]
            deleted_count = original_count - len(remaining_orders)
            
            if deleted_count == 0:
                return False, "æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            
            # å‰Šé™¤ã•ã‚ŒãŸæ³¨æ–‡ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤
            deleted_orders = [order for order in all_orders if order['timestamp'] == timestamp]
            for order in deleted_orders:
                image_path = os.path.join(LINE_ORDERS_DIR, order['image_filename'])
                if os.path.exists(image_path):
                    os.remove(image_path)
            
            # æ®‹ã‚Šã®æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            with open(orders_file, "w", encoding="utf-8") as f:
                json.dump(remaining_orders, f, ensure_ascii=False, indent=4)
        
        return True, f"ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
    except Exception as e:
        return False, f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}"

# ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ç®¡ç†é–¢æ•°ç¾¤
def _text_orders_file():
    """ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—"""
    return os.path.join(TEXT_ORDERS_DIR, "orders.json")

def save_text_order_data(account, customer_name, message_text, delivery_date_opt=None):
    """
    ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    """
    try:
        jst = timezone(timedelta(hours=9))
        now = datetime.now(jst)
        order_date = now.strftime("%Y/%m/%d")
        ts = now.strftime("%Y%m%d_%H%M%S_%f")

        data = {
            "account": account,
            "customer_name": customer_name.strip(),
            "message_text": message_text.strip(),
            "order_date": order_date,
            "delivery_date_opt": delivery_date_opt or "",
            "timestamp": ts,
            "processed": False,
            "parsed_data": None
        }

        path = _text_orders_file()
        with get_file_lock(path):
            arr = []
            if os.path.exists(path):
                with open(path, "r", encoding="utf-8") as f:
                    arr = json.load(f)
            arr.append(data)
            with open(path, "w", encoding="utf-8") as f:
                json.dump(arr, f, ensure_ascii=False, indent=4)
        return True, "ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚", ts
    except Exception as e:
        return False, f"ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}", None

def get_text_orders_for_user(account):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é–¢é€£ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    """
    try:
        path = _text_orders_file()
        if not os.path.exists(path):
            return []
        with open(path, "r", encoding="utf-8") as f:
            all_ = json.load(f)
        return [o for o in all_ if o.get("account") == account]
    except Exception as e:
        print(f"get_text_orders_for_user error: {e}")
        return []

def save_parsed_text_order_data(timestamp, parsed):
    """
    ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ã®è§£æçµæœã‚’ä¿å­˜
    """
    try:
        path = _text_orders_file()
        if not os.path.exists(path):
            return False, "ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“"
        with get_file_lock(path):
            with open(path, "r", encoding="utf-8") as f:
                arr = json.load(f)
            updated = False
            for o in arr:
                if o["timestamp"] == timestamp and not o.get("processed", False):
                    o["parsed_data"] = parsed
                    o["processed"] = True
                    updated = True
                    break
            if not updated:
                # å¿µã®ãŸã‚äºŒæ®µéšç›®ï¼ˆåŒtimestampå¼·åˆ¶æ›´æ–°ï¼‰
                for o in arr:
                    if o["timestamp"] == timestamp:
                        o["parsed_data"] = parsed
                        o["processed"] = True
                        updated = True
                        break
            with open(path, "w", encoding="utf-8") as f:
                json.dump(arr, f, ensure_ascii=False, indent=4)
        return True, "è§£æçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ"
    except Exception as e:
        return False, f"è§£æçµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"

def delete_text_order_by_timestamp(timestamp):
    """
    æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    """
    try:
        path = _text_orders_file()
        if not os.path.exists(path):
            return False, "ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“"
        with get_file_lock(path):
            with open(path, "r", encoding="utf-8") as f:
                arr = json.load(f)
            new_arr = [o for o in arr if o["timestamp"] != timestamp]
            with open(path, "w", encoding="utf-8") as f:
                json.dump(new_arr, f, ensure_ascii=False, indent=4)
        return True, "ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
    except Exception as e:
        return False, f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}"

def delete_processed_text_orders():
    """
    å‡¦ç†æ¸ˆã¿ã®ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    """
    try:
        path = _text_orders_file()
        if not os.path.exists(path):
            return True, "å‰Šé™¤å¯¾è±¡ãªã—"
        with get_file_lock(path):
            with open(path, "r", encoding="utf-8") as f:
                arr = json.load(f)
            remain = [o for o in arr if not o.get("processed", False)]
            deleted = len(arr) - len(remain)
            with open(path, "w", encoding="utf-8") as f:
                json.dump(remain, f, ensure_ascii=False, indent=4)
        return True, f"{deleted}ä»¶ã®å‡¦ç†æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
    except Exception as e:
        return False, f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}"

def parse_text_order_with_openai(customer_name, message_text, order_date, delivery_date_override=""):
    """
    OpenAI APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ã‚’è§£æ
    """
    try:
        api_key = get_openai_api_key()
        if not api_key:
            raise Exception("OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        import openai
        client = openai.OpenAI(api_key=api_key)

        system_prompt = get_text_order_prompt()
        user_text = (
            f"é¡§å®¢å: {customer_name}\n"
            f"å—ä¿¡æ—¥(åŸºæº–æ—¥): {order_date}\n"
            f"æœ¬æ–‡:\n{message_text}\n"
            "ä¸Šè¨˜ã‚’è§£æã—ã¦æ§‹é€ åŒ–JSONã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        )

        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role":"system","content":system_prompt},
                      {"role":"user","content":user_text}],
            max_tokens=2000,
            temperature=0.1
        )
        content = resp.choices[0].message.content.strip()
        if content.startswith("```json"):
            content = content[7:]
        if content.endswith("```"):
            content = content[:-3]
        parsed = json.loads(content)

        # æœ€ä½é™ã®è£œæ­£ï¼ˆç™ºæ³¨æ—¥/ç´å“æ—¥ï¼‰
        if not parsed.get("order_date"):
            parsed["order_date"] = order_date
        if delivery_date_override:
            parsed["delivery_date"] = delivery_date_override
        if not parsed.get("partner_name"):
            parsed["partner_name"] = customer_name
        return parsed
    except Exception as e:
        raise Exception(f"ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡è§£æã‚¨ãƒ©ãƒ¼: {e}")

def parse_line_order_with_openai(image_path, sender_name, message_text="", order_date=""):
    """
    OpenAI APIã‚’ä½¿ç”¨ã—ã¦LINEæ³¨æ–‡ç”»åƒã‚’è§£æ
    """
    try:
        api_key = get_openai_api_key()
        if not api_key:
            raise Exception("OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        import openai
        client = openai.OpenAI(api_key=api_key)
        
        # ç”»åƒã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        system_prompt = get_line_order_prompt()
        
        # å—ä¿¡æ—¥æ™‚ã‚’å«ã‚€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        user_message = f"é€ä¿¡è€…: {sender_name}\nå—ä¿¡æ—¥: {order_date}\nãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {message_text}\n\nã“ã®LINEæ³¨æ–‡ã‚’è§£æã—ã¦ãã ã•ã„ã€‚å—ä¿¡æ—¥ã‚’åŸºæº–ã«ç´å“æ—¥ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚"
        
        # OpenAI APIã‚’å‘¼ã³å‡ºã—
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_message},
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_data}"}}
                    ]
                }
            ],
            max_tokens=2000,
            temperature=0.1
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
        content = response.choices[0].message.content
        
        # JSONã¨ã—ã¦è§£æ
        try:
            cleaned_content = content.strip()
            if cleaned_content.startswith('```json'):
                cleaned_content = cleaned_content[7:]
            if cleaned_content.endswith('```'):
                cleaned_content = cleaned_content[:-3]
            cleaned_content = cleaned_content.strip()
            
            parsed_data = json.loads(cleaned_content)
            
            # ç™ºæ³¨æ—¥ãŒç©ºã®å ´åˆã¯å—ä¿¡æ—¥ã‚’è¨­å®š
            if not parsed_data.get("order_date"):
                parsed_data["order_date"] = order_date
            
            return parsed_data
        except json.JSONDecodeError as e:
            raise Exception(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
            
    except Exception as e:
        raise Exception(f"LINEæ³¨æ–‡è§£æã‚¨ãƒ©ãƒ¼: {e}")

def extract_pdf_images(pdf_bytes):
    """
    PDFã‹ã‚‰ãƒšãƒ¼ã‚¸å…¨ä½“ã‚’ç”»åƒã¨ã—ã¦æŠ½å‡ºã—ã¦PIL Imageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
    """
    try:
        with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
            page_images = []
            for page_num, page in enumerate(pdf.pages):
                try:
                    # ãƒšãƒ¼ã‚¸ã‚’ç”»åƒã¨ã—ã¦ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
                    page_image = page.to_image()
                    if page_image:
                        pil_image = page_image.original
                        page_images.append({
                            'page': page_num + 1,
                            'image': pil_image
                        })
                except Exception as e:
                    st.warning(f"ãƒšãƒ¼ã‚¸ {page_num + 1} ã®ç”»åƒåŒ–ã«å¤±æ•—: {e}")
            
            return page_images
    except Exception as e:
        st.error(f"PDFç”»åƒæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return []

def display_pdf_images(images, filename):
    """
    PDFã‹ã‚‰æŠ½å‡ºã—ãŸãƒšãƒ¼ã‚¸ç”»åƒã‚’Webä¸Šã«è¡¨ç¤º
    """
    if not images:
        st.info(f"{filename} ã‹ã‚‰ç”»åƒã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    st.subheader(f"ğŸ“„ {filename} ã®ç”»åƒè¡¨ç¤º")
    
    # ãƒšãƒ¼ã‚¸ç”»åƒã‚’è¡¨ç¤º
    if len(images) == 1:
        img_data = images[0]
        st.write(f"**ãƒšãƒ¼ã‚¸ {img_data['page']}**")
        st.image(img_data['image'], caption=f"ãƒšãƒ¼ã‚¸ {img_data['page']}", width=400)
    else:
        # è¤‡æ•°ãƒšãƒ¼ã‚¸ã®å ´åˆã¯2ãƒšãƒ¼ã‚¸ãšã¤1è¡Œã§è¡¨ç¤º
        for i in range(0, len(images), 2):
            cols = st.columns(2)
            for j in range(2):
                if i + j < len(images):
                    img_data = images[i + j]
                    with cols[j]:
                        st.write(f"**ãƒšãƒ¼ã‚¸ {img_data['page']}**")
                        st.image(img_data['image'], caption=f"ãƒšãƒ¼ã‚¸ {img_data['page']}", width=400)

def is_admin(username):
    """
    ç®¡ç†è€…ã‹ã©ã†ã‹ã‚’åˆ¤å®š
    """
    # ç®¡ç†è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®ãƒªã‚¹ãƒˆ
    admin_emails = [
        "n.hatakeyama@agrilive.co.jp"  # å®Ÿéš›ã®ç®¡ç†è€…ãƒ¡ãƒ¼ãƒ«
    ]
    return username in admin_emails

def get_all_users():
    """å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—ï¼ˆYAMLã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰"""
    try:
        cfg = load_credentials_from_yaml()
        all_users = []
        for email, u in cfg['credentials']['usernames'].items():
            # ä½œæˆæ—¥ã‚’é©åˆ‡ãªå½¢å¼ã«è¨­å®š
            # åŸºæœ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å ´åˆã¯å›ºå®šæ—¥ä»˜ã€æ–°è¦è¿½åŠ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å ´åˆã¯ä¿å­˜ã•ã‚ŒãŸä½œæˆæ—¥ã‚’ä½¿ç”¨
            if email in BASIC_USERS:
                created_date = "2024/01/01"  # åŸºæœ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæˆæ—¥
            else:
                # æ–°è¦è¿½åŠ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å ´åˆã¯ä¿å­˜ã•ã‚ŒãŸä½œæˆæ—¥ã‚’ä½¿ç”¨
                created_date = u.get("created_date", "2024/01/01")  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
            all_users.append({
                "email": email,
                "name": u.get("name", ""),
                "company": u.get("company", ""),
                "created_date": created_date
            })
        return all_users
    except Exception as e:
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def load_docx_html(filepath):
    doc = Document(filepath)
    html = ""
    for para in doc.paragraphs:
        # ç©ºè¡Œã‚‚æ”¹è¡Œã¨ã—ã¦åæ˜ 
        html += f"{para.text}<br>"
    return html

def detect_csv_type(content_bytes):
    ENCODINGS = ["utf-8-sig", "utf-8", "cp932", "shift_jis"]
    debug_log = []
    for enc in ENCODINGS:
        try:
            file_str = content_bytes.decode(enc)
            sio = io.StringIO(file_str)
            first_line = sio.readline().strip().split(",")
            debug_log.append(f"[{enc}] first_line={first_line}")
            cell0 = first_line[0].replace('"', '').replace("'", '').strip() if first_line else ""
            if cell0 == "H":
                debug_log.append(f"åˆ¤å®š: infomart ({enc})")
                return 'infomart', enc, debug_log
            elif cell0 == "ä¼ç¥¨ç•ªå·":
                debug_log.append(f"åˆ¤å®š: iporter ({enc})")
                return 'iporter', enc, debug_log
        except Exception as e:
            debug_log.append(f"[{enc}] error: {e}")
    debug_log.append("åˆ¤å®š: unknown")
    return 'unknown', None, debug_log

def validate_email(email):
    """
    ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®å½¢å¼ã‚’æ¤œè¨¼ã™ã‚‹
    """
    import re
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    if not re.match(pattern, email):
        return False, "æœ‰åŠ¹ãªãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    return True, "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¯æœ‰åŠ¹ã§ã™"

def validate_password(password):
    """
    ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®å¼·åº¦ã‚’æ¤œè¨¼ã™ã‚‹
    """
    if len(password) < 6:
        return False, "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯6æ–‡å­—ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
    
    return True, "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯æœ‰åŠ¹ã§ã™"







# --- èªè¨¼ï¼ˆYAMLçµ±åˆã«ã‚ˆã‚Šå‰Šé™¤ï¼‰ ---
# load_credentials() é–¢æ•°ã¯å‰Šé™¤ - YAMLä¸€æœ¬åŒ–
# base_credentials ã‚‚å‰Šé™¤ - YAMLä¸€æœ¬åŒ–

# --- YAMLãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç† ---
import yaml
from yaml import SafeLoader, safe_dump

# åŸºæœ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©
BASIC_USERS = {
    'n.hatakeyama@agrilive.co.jp': {
        'email': 'n.hatakeyama@agrilive.co.jp',
        'name': 'ç• å±± ç›´å·±',
        'company': 'ã‚¢ã‚°ãƒªãƒ©ã‚¤ãƒ–æ ªå¼ä¼šç¤¾',
        'password': '$2b$12$uUoqP0QH.DBO2df028wtS.Vi91jYA4KLVulsatVAuFsY/m.9HWtku'
    },
    'hatake.hatake.hatake7@outlook.jp': {
        'email': 'hatake.hatake.hatake7@outlook.jp',
        'name': 'ã¯ãŸã‘ã‚„ã¾',
        'company': 'ã‚¢ã‚°ãƒªãƒ©ã‚¤ãƒ–æ ªå¼ä¼šç¤¾',
        'password': '$2b$12$CBwB/tQCRJjyPEENHElWM.oKF69dzmSVREmoQ179JMnTvoayEAtPK'
    }
}

def _seed_config():
    """åŸºæœ¬è¨­å®šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¿”ã™"""
    return {
        'credentials': {'usernames': {}},
        'cookie': {'expiry_days': 30, 'key': 'some_signature_key', 'name': 'some_cookie_name'},
        'preauthorized': {'emails': ['melsby@gmail.com']}
    }

def load_credentials_from_yaml(use_lock=True):
    """YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€ï¼ˆèª­ã¿è¾¼ã¿å°‚ç”¨ã€å‰¯ä½œç”¨ãªã—ï¼‰"""
    print(f"èªè¨¼æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {CRED_PATH}")
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    CRED_PATH.parent.mkdir(parents=True, exist_ok=True)
    
    def _load_without_lock():
        if not CRED_PATH.exists():
            # åˆå›ã®ã¿ seed ã‚’è¿”ã™ï¼ˆã“ã“ã§ã¯ä¿å­˜ã—ãªã„ï¼‰
            print("èªè¨¼æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€åŸºæœ¬è¨­å®šã‚’è¿”ã—ã¾ã™")
            cfg = _seed_config()
            return cfg
        
        try:
            with open(CRED_PATH, "r", encoding="utf-8") as f:
                cfg = yaml.safe_load(f) or {}
        except yaml.YAMLError as e:
            # ã“ã“ã§ãƒ†ãƒ³ãƒ—ãƒ¬ã«æˆ»ã—ã¦è¿”ã•ãªã„ï¼ˆä¸Šæ›¸ãæ¶ˆå¤±ã‚’é˜²ãï¼‰
            error_msg = f"credentials.yml ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§: {e}"
            print(error_msg)
            raise RuntimeError(error_msg)
        
        # æœ€ä½é™ã®æ§‹é€ ã‚’ä¿éšœï¼ˆã“ã“ã§ã‚‚ä¿å­˜ã—ãªã„ï¼‰
        cfg.setdefault('credentials', {}).setdefault('usernames', {})
        cfg.setdefault('cookie', {'expiry_days': 30, 'key': 'some_signature_key', 'name': 'some_cookie_name'})
        cfg.setdefault('preauthorized', {'emails': ['melsby@gmail.com']})
        
        users = cfg['credentials']['usernames']
        print(f"YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿: {len(users)} ãƒ¦ãƒ¼ã‚¶ãƒ¼")
        
        # å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è©³ç´°ã‚’è¡¨ç¤º
        for email, user_data in users.items():
            print(f"  ãƒ¦ãƒ¼ã‚¶ãƒ¼: {email} ({user_data.get('name', 'N/A')}, {user_data.get('company', 'N/A')})")
        
        return cfg
    
    if use_lock:
        # èª­ã¿è¾¼ã¿å°‚ç”¨ï¼ˆä¿å­˜ã®å‰¯ä½œç”¨ã‚’ç„¡ãã™ï¼‰
        with _with_creds_lock():
            return _load_without_lock()
    else:
        # ãƒ­ãƒƒã‚¯ãªã—ã§èª­ã¿è¾¼ã¿ï¼ˆæ—¢ã«ãƒ­ãƒƒã‚¯ã‚’å–å¾—ã—ã¦ã„ã‚‹å ´åˆï¼‰
        return _load_without_lock()

def save_credentials_to_yaml(config, use_lock=True) -> bool:
    """èªè¨¼æƒ…å ±ã‚’YAMLãƒ•ã‚¡ã‚¤ãƒ«ã«åŸå­çš„ã«ä¿å­˜"""
    try:
        print("èªè¨¼æƒ…å ±ä¿å­˜é–‹å§‹")
        
        def _save_without_lock():
            print("YAMLå½¢å¼ã«å¤‰æ›ä¸­...")
            text = yaml.safe_dump(config, allow_unicode=True, sort_keys=True)
            print(f"YAMLãƒ†ã‚­ã‚¹ãƒˆé•·: {len(text)} æ–‡å­—")
            
            print("åŸå­çš„æ›¸ãè¾¼ã¿å®Ÿè¡Œä¸­...")
            _atomic_write_text(CRED_PATH, text)
        
        if use_lock:
            with _with_creds_lock():
                _save_without_lock()
        else:
            _save_without_lock()
        
        print(f"èªè¨¼æƒ…å ±ä¿å­˜æˆåŠŸ: {CRED_PATH}")
        return True
    except Exception as e:
        print(f"YAMLãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        print(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼è©³ç´°: {traceback.format_exc()}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡æ˜“ä¿å­˜ã‚’è©¦è¡Œ
        try:
            print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¿å­˜ã‚’è©¦è¡Œä¸­...")
            CRED_PATH.parent.mkdir(parents=True, exist_ok=True)
            with open(CRED_PATH, "w", encoding="utf-8") as f:
                yaml.safe_dump(config, f, allow_unicode=True, sort_keys=True)
            print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¿å­˜æˆåŠŸ")
            return True
        except Exception as fallback_e:
            print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¿å­˜ã‚‚å¤±æ•—: {fallback_e}")
            return False

def add_user_to_yaml(email, name, company, password_hash):
    """YAMLãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¿½åŠ ã™ã‚‹ï¼ˆãƒ­ãƒƒã‚¯ä»˜ãï¼‰"""
    print(f"add_user_to_yamlé–‹å§‹: {email}")
    
    try:
        print("ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ã‚’å–å¾—ä¸­...")
        with _with_creds_lock():
            print("ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯å–å¾—å®Œäº†")
            
            print("èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            cfg = load_credentials_from_yaml(use_lock=False)  # ãƒ­ãƒƒã‚¯ãªã—ã§èª­ã¿è¾¼ã¿
            print(f"èª­ã¿è¾¼ã¿æ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(cfg['credentials']['usernames'])}")
            print(f"èª­ã¿è¾¼ã¿æ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼: {list(cfg['credentials']['usernames'].keys())}")
            
            print("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¿½åŠ ä¸­...")
            # ä½œæˆæ—¥ã‚’è¨˜éŒ²
            from datetime import datetime
            created_date = datetime.now().strftime("%Y/%m/%d")
            
            cfg['credentials']['usernames'][email] = {
                "email": email, "name": name, "company": company, "password": password_hash, "created_date": created_date
            }
            
            print(f"è¿½åŠ å¾Œãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(cfg['credentials']['usernames'])}")
            print(f"è¿½åŠ å¾Œãƒ¦ãƒ¼ã‚¶ãƒ¼: {list(cfg['credentials']['usernames'].keys())}")
            
            print("èªè¨¼æƒ…å ±ã‚’ä¿å­˜ä¸­...")
            ok = save_credentials_to_yaml(cfg, use_lock=False)  # ãƒ­ãƒƒã‚¯ãªã—ã§ä¿å­˜
            if not ok:
                print("ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            print("ä¿å­˜å®Œäº†")
        
        print("ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯è§£æ”¾å®Œäº†")
        
        # ä¿å­˜å¾Œã«èª­ã¿ç›´ã—ã¦ UI å´ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚æ›´æ–°
        print("ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°ä¸­...")
        st.session_state['credentials_config'] = load_credentials_from_yaml()
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ æˆåŠŸï¼ˆYAMLï¼‰: {email}")
        return True
    except Exception as e:
        print(f"YAMLãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {traceback.format_exc()}")
        return False

# ensure_basic_usersé–¢æ•°ã¯å‰Šé™¤ - åˆæœŸåŒ–ãƒ­ã‚¸ãƒƒã‚¯ã®å¤‰æ›´ã«ã‚ˆã‚Šä¸è¦

def check_user_exists_in_yaml(email):
    """YAMLãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å­˜åœ¨ã‚’ç¢ºèªã™ã‚‹"""
    try:
        config = load_credentials_from_yaml()
        return email in config['credentials']['usernames']
    except Exception as e:
        print(f"YAMLãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return False

def show_yaml_contents():
    """YAMLãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è¡¨ç¤ºã™ã‚‹"""
    try:
        config = load_credentials_from_yaml()
        st.sidebar.markdown("---")
        st.sidebar.subheader("ğŸ“„ YAMLãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
        for email, user_data in config['credentials']['usernames'].items():
            st.sidebar.info(f"**{email}**")
            st.sidebar.info(f"  åå‰: {user_data.get('name', 'N/A')}")
            st.sidebar.info(f"  ä¼šç¤¾: {user_data.get('company', 'N/A')}")
            st.sidebar.info(f"  ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰: {user_data.get('password', 'N/A')[:20]}...")
        
    except Exception as e:
        st.sidebar.error(f"YAMLãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")

def add_user(email, name, company, password):
    """
    å‹•çš„ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¿½åŠ ã™ã‚‹ï¼ˆYAMLãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨ï¼‰
    """
    import os
    
    print(f"add_useré–‹å§‹: email={email}, name={name}, company={company}")
    
    # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹å½¢å¼ãƒã‚§ãƒƒã‚¯
    is_valid_email, email_message = validate_email(email)
    print(f"ãƒ¡ãƒ¼ãƒ«ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³: {is_valid_email}, {email_message}")
    if not is_valid_email:
        return False, email_message
    
    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å¼·åº¦ãƒã‚§ãƒƒã‚¯
    is_valid_pw, pw_message = validate_password(password)
    print(f"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³: {is_valid_pw}, {pw_message}")
    if not is_valid_pw:
        return False, pw_message
    
    # YAMLãƒ•ã‚¡ã‚¤ãƒ«ã§é‡è¤‡ãƒã‚§ãƒƒã‚¯
    if check_user_exists_in_yaml(email):
        print(f"é‡è¤‡ã‚¨ãƒ©ãƒ¼: {email} ã¯æ—¢ã«ç™»éŒ²æ¸ˆã¿")
        return False, "ã“ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¯æ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™ã€‚"
    
    # æ­£ã—ã„ãƒãƒƒã‚·ãƒ¥åŒ–æ–¹æ³•ï¼ˆbcryptç›´æ¥ä½¿ç”¨ï¼‰
    import bcrypt
    hashed_pw = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
    
    # YAMLãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¿½åŠ 
    save_result = add_user_to_yaml(email, name, company, hashed_pw)
    print(f"ä¿å­˜çµæœ: {save_result}")
    if save_result:
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ æˆåŠŸ: {email}")
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ç¢ºå®Ÿã«æ›´æ–°
        try:
            st.session_state['credentials_config'] = load_credentials_from_yaml(use_lock=True)
            print("ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹æ›´æ–°å®Œäº†")
        except Exception as e:
            print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        return True, "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚"
    else:
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ å¤±æ•—: {email}")
        return False, "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

st.set_page_config(page_title="å—æ³¨é›†è¨ˆã‚¢ãƒ—ãƒª", layout="wide")

# èªè¨¼æƒ…å ±ã‚’åˆæœŸåŒ–ï¼ˆé–¢æ•°å®šç¾©å¾Œã«ç§»å‹•ï¼‰
# èµ·å‹•ç›´å¾Œï¼ˆauthenticator ä½œæˆå‰ï¼‰ã«ä¸€åº¦ã ã‘å®Ÿè¡Œ
print("=== èªè¨¼æƒ…å ±åˆæœŸåŒ–é–‹å§‹ ===")

try:
    if not CRED_PATH.exists():
        # åˆå›ã®ã¿ï¼šseed + BASIC_USERS ã‚’ä½œã£ã¦ä¿å­˜
        print("åˆå›ä½œæˆï¼šåŸºæœ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å«ã‚€è¨­å®šã‚’ä½œæˆã—ã¾ã™")
        cfg = _seed_config()
        cfg['credentials']['usernames'].update(BASIC_USERS)
        save_credentials_to_yaml(cfg)  # â† å¿…ãšä¿å­˜
        credentials_config = cfg
    else:
        # 2å›ç›®ä»¥é™ï¼šç´”ç²‹ã«èª­ã‚€ã ã‘ï¼ˆå‰¯ä½œç”¨ãªã—ï¼‰
        print("æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™")
        credentials_config = load_credentials_from_yaml()
    print("=== èªè¨¼æƒ…å ±åˆæœŸåŒ–å®Œäº† ===")
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    total_users = len(credentials_config['credentials']['usernames'])
    print(f"èªè¨¼æƒ…å ±: ç·ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°={total_users}")
    
    # è©³ç´°ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    print("=== èªè¨¼æƒ…å ±è©³ç´° ===")
    print(f"å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼: {list(credentials_config['credentials']['usernames'].keys())}")
    
    # å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è©³ç´°æƒ…å ±
    for email, user_data in credentials_config['credentials']['usernames'].items():
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼è©³ç´° - {email}:")
        print(f"  åå‰: {user_data.get('name', 'N/A')}")
        print(f"  ä¼šç¤¾: {user_data.get('company', 'N/A')}")
        print(f"  ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰é•·: {len(user_data.get('password', ''))}")
        print(f"  ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å…ˆé ­: {user_data.get('password', '')[:20]}...")

except Exception as e:
    st.error(f"èªè¨¼æƒ…å ±ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.stop()  # ã“ã“ã§ä¸­æ–­ã€‚seedã«å·®ã—æ›¿ãˆãªã„

authenticator = stauth.Authenticate(
    credentials=credentials_config['credentials'],
    cookie_name=credentials_config['cookie']['name'],
    key=credentials_config['cookie']['key'],
    expiry_days=credentials_config['cookie']['expiry_days'],
    preauthorized=credentials_config['preauthorized']
)

# --- ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã‚’æç”»ï¼ˆå¿…ãšã“ã“ã§è¡¨ç¤ºï¼ï¼‰ ---
authenticator.login(
    location='main',
    fields={
        "Form name": "ãƒ­ã‚°ã‚¤ãƒ³",
        "Username": "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹",
        "Password": "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰",
        "Login": "ãƒ­ã‚°ã‚¤ãƒ³"
    }
)

# --- ãƒ­ã‚°ã‚¤ãƒ³ç”»é¢ã®ä¸‹ã«è¦ç´„ã‚’è¡¨ç¤ºï¼ˆã“ã“ã§é †åºèª¿æ•´ï¼‰ ---
if not st.session_state.get("authentication_status"):
    st.markdown("---")
    if 'view_select' not in locals():
        view_select = "è¡¨ç¤ºã—ãªã„"  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç›´å¾Œã®å†å®Ÿè¡Œå¯¾ç­–
    if view_select == "åˆ©ç”¨è¦ç´„":
        html = load_docx_html("åˆ©ç”¨è¦ç´„.docx")
        st.markdown("### åˆ©ç”¨è¦ç´„")
        st.markdown(html, unsafe_allow_html=True)
    elif view_select == "ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼":
        html = load_docx_html("ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼.docx")
        st.markdown("### ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼")
        st.markdown(html, unsafe_allow_html=True)
    # ä½•ã‚‚é¸æŠã—ãªã‘ã‚Œã°ä½•ã‚‚å‡ºã•ãªã„

# --- ãƒ­ã‚°ã‚¤ãƒ³å¾Œã®ç”»é¢ ---
if st.session_state.get("authentication_status"):
    username = st.session_state.get("username", "")
    name = st.session_state.get("name", "")
    config = load_config(user_id=username)
    
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
    init_db()
    # DBæƒ…å ±ã¯ç®¡ç†è€…ã®ã¿è¡¨ç¤º
    if is_admin(username):
        st.sidebar.info(f"DB: {DB_PATH}")
        st.sidebar.info(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {DATA_DIR}")
        st.sidebar.info(f"LINEæ³¨æ–‡: {LINE_ORDERS_DIR}")
        st.sidebar.info(f"ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡: {TEXT_ORDERS_DIR}")
        st.sidebar.info(f"èªè¨¼YAML: {CRED_PATH}")
    
    # ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒœã‚¿ãƒ³ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ç§»å‹•
    st.sidebar.markdown("---")
    if st.sidebar.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°", key="refresh_data_sidebar"):
        st.rerun()
    
    # ãƒ¡ã‚¤ãƒ³ç”»é¢ã®ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†ï¼ˆç©ºç™½ã‚’è©°ã‚ã‚‹ï¼‰
    col1, col2 = st.columns([4, 1])
    
    with col1:
        st.title("å—æ³¨é›†è¨ˆã‚¢ãƒ—ãƒª")
        st.success(f"{name} ã•ã‚“ã€ã‚ˆã†ã“ãï¼")
    
    with col2:
        # ãƒ­ã‚´ã‚’å³ä¸Šã«é…ç½®
        st.image("ä¼šç¤¾ãƒ­ã‚´.png", width=120)
    
    # LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“± LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿")
    
    # æœ€æ–°ã®LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
    line_orders = get_line_orders_for_user(username)
    if line_orders:
        st.sidebar.success(f"ğŸ“± LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿: {len(line_orders)}ä»¶")
        latest_orders = sorted(line_orders, key=lambda x: x['timestamp'], reverse=True)[:3]
        for i, order in enumerate(latest_orders):
            with st.sidebar.expander(f"ğŸ“‹ {order['sender_name']} - {order['order_date']}"):
                st.write(f"**é€ä¿¡è€…**: {order['sender_name']}")
                st.write(f"**å—ä¿¡æ—¥**: {order['order_date']}")
                if order.get('processed', False):
                    st.success("âœ… å‡¦ç†æ¸ˆã¿")
                else:
                    st.warning("â³ æœªå‡¦ç†")
                
                # å‰Šé™¤ãƒœã‚¿ãƒ³ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å«ã‚ã¦ã‚­ãƒ¼ã‚’ãƒ¦ãƒ‹ãƒ¼ã‚¯ã«ã™ã‚‹ï¼‰
                if st.sidebar.button(f"ğŸ—‘ï¸ å‰Šé™¤", key=f"sidebar_delete_{i}_{order['timestamp']}"):
                    success, message = delete_line_order_by_timestamp(order['timestamp'])
                    if success:
                        st.sidebar.success(message)
                        st.rerun()
                    else:
                        st.sidebar.error(message)
    else:
        st.sidebar.info("LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“")
        st.sidebar.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {username}")
    
    # ç®¡ç†è€…ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
    try:
        if is_admin(username):
            st.sidebar.markdown("---")
            st.sidebar.subheader("ç®¡ç†è€…ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
            
            if st.sidebar.button("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ³ç¢ºèª"):
                st.session_state.show_admin_dashboard = True
            
            if st.sidebar.button("é€šå¸¸ç”»é¢ã«æˆ»ã‚‹"):
                st.session_state.show_admin_dashboard = False
        
        # ç®¡ç†è€…ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®è¡¨ç¤º
        if is_admin(username) and st.session_state.get("show_admin_dashboard", False):
            st.markdown("---")
            st.subheader("ğŸ“Š ç®¡ç†è€…ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
            
            # çµ±è¨ˆæƒ…å ±
            all_users = get_all_users()
            # æ—§ãƒ­ã‚¸ãƒƒã‚¯ã¯å‰Šé™¤
            # base_users = [u for u in all_users if u["type"] == "åŸºæœ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆSecret Filesï¼‰"]
            # dynamic_users = [u for u in all_users if u["type"] == "å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼"]
            
            yaml_users = all_users  # ã“ã‚ŒãŒå…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ç·ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°", len(yaml_users))
            with col2:
                # åŸºæœ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆ@agrilive.co.jpï¼‰ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                basic_count = len([u for u in yaml_users if "@agrilive.co.jp" in u["email"]])
                st.metric("åŸºæœ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°", basic_count)
            with col3:
                # ãã®ä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                other_count = len([u for u in yaml_users if "@agrilive.co.jp" not in u["email"]])
                st.metric("ãã®ä»–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°", other_count)
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§
            st.subheader("ğŸ‘¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§")
            
            if all_users:
                # DataFrameã«å¤‰æ›ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ã‚¤ãƒ—åˆ—ã‚’å‰Šé™¤ï¼‰
                df_users = pd.DataFrame(all_users)
                df_users = df_users[["email", "name", "company", "created_date"]]
                df_users.columns = ["ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", "ãŠåå‰", "ä¼šç¤¾å", "ä½œæˆæ—¥"]
                
                st.dataframe(
                    df_users,
                    use_container_width=True,
                    hide_index=True
                )
                
                # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
                csv = df_users.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv,
                    file_name=f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    mime="text/csv"
                )
            else:
                st.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            
            # LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿æƒ…å ±
            st.subheader("ğŸ“± LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿æƒ…å ±")
            
            all_line_orders = get_all_line_orders()
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ç·LINEæ³¨æ–‡æ•°", len(all_line_orders))
            with col2:
                processed_orders = [order for order in all_line_orders if order.get("processed", False)]
                st.metric("å‡¦ç†æ¸ˆã¿æ³¨æ–‡æ•°", len(processed_orders))
            
            # å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ãƒœã‚¿ãƒ³
            if processed_orders:
                if st.button("ğŸ—‘ï¸ å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å‰Šé™¤", type="secondary"):
                    success, message = delete_processed_line_orders()
                    if success:
                        st.success(message)
                        st.rerun()
                    else:
                        st.error(message)
            
            # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
            st.subheader("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
            col1, col2 = st.columns(2)
            
            with col1:
                st.info(f"**ç’°å¢ƒ**: {'æœ¬ç•ªç’°å¢ƒ' if is_production() else 'é–‹ç™ºç’°å¢ƒ'}")
                st.info(f"**ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼**: {username}")
            
            with col2:
                st.info(f"**èªè¨¼æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«**: {CRED_PATH}")
                st.info(f"**ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼**: YAML")
            
            st.stop()  # ç®¡ç†è€…ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºæ™‚ã¯é€šå¸¸ã®æ©Ÿèƒ½ã‚’ã‚¹ã‚­ãƒƒãƒ—
    except Exception as e:
        st.error(f"ç®¡ç†è€…ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯é€šå¸¸ã®æ©Ÿèƒ½ã‚’ç¶šè¡Œ

    # ãƒ‡ãƒãƒƒã‚°ç”¨: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æƒ…å ±ã®ç¢ºèªï¼ˆé–‹ç™ºæ™‚ã®ã¿è¡¨ç¤ºï¼‰
    if not is_production():
        st.sidebar.markdown("---")
        st.sidebar.subheader("ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æƒ…å ±")
        import os
        current_dir = os.getcwd()
        st.sidebar.info(f"ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {current_dir}")
        
        # YAMLãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        yaml_exists = CRED_PATH.exists()
        yaml_status = "âœ… å­˜åœ¨" if yaml_exists else "âŒ ä¸å­˜åœ¨"
        st.sidebar.info(f"YAMLãƒ•ã‚¡ã‚¤ãƒ«: {yaml_status}")
        
        if yaml_exists:
            try:
                size = CRED_PATH.stat().st_size
                st.sidebar.info(f"  - ã‚µã‚¤ã‚º: {size} bytes")
            except:
                pass

    # ç’°å¢ƒæƒ…å ±è¡¨ç¤ºï¼ˆç®¡ç†è€…ã®ã¿ï¼‰
    if is_admin(username):
        st.sidebar.markdown("---")
        st.sidebar.subheader("ğŸ” ç’°å¢ƒæƒ…å ±ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰")
        st.sidebar.info(f"RENDER: {os.getenv('RENDER')}")
        st.sidebar.info(f"ENV: {os.getenv('ENV')}")
        st.sidebar.info(f"is_production(): {is_production()}")
        st.sidebar.info(f"OpenAI API Key: {'è¨­å®šæ¸ˆã¿' if get_openai_api_key() else 'æœªè¨­å®š'}")

    # OpenAI APIã‚­ãƒ¼è¨­å®šï¼ˆé–‹ç™ºç’°å¢ƒã®ã¿ï¼‰
    if not is_production():
        st.sidebar.markdown("---")
        st.sidebar.subheader("OpenAI APIè¨­å®šï¼ˆé–‹ç™ºç’°å¢ƒï¼‰")
        
        # ç¾åœ¨ã®APIã‚­ãƒ¼ã‚’å–å¾—
        try:
            current_key = get_openai_api_key()
            api_key = st.sidebar.text_input(
                "OpenAI APIã‚­ãƒ¼",
                value=current_key,
                type="password",
                help="PDFè§£æã«å¿…è¦ãªOpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
            )
            
            if api_key and api_key != current_key:
                # æ–°ã—ã„APIã‚­ãƒ¼ã‚’è¨­å®š
                os.environ['OPENAI_API_KEY'] = api_key
                st.sidebar.success("APIã‚­ãƒ¼ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸ")
            elif api_key:
                st.sidebar.success("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
            else:
                st.sidebar.warning("PDFè§£æã«ã¯APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")
        except Exception as e:
            st.sidebar.error(f"APIã‚­ãƒ¼ã®å–å¾—ã«å¤±æ•—: {e}")
            st.sidebar.info("ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºæ™‚ã¯.envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„")
    else:
        # æœ¬ç•ªç’°å¢ƒã®å ´åˆ - APIã‚­ãƒ¼æƒ…å ±ã¯è¡¨ç¤ºã—ãªã„
        pass
    
    # ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®æœ€å¾Œã«é…ç½®
    st.sidebar.markdown("---")
    authenticator.logout('ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ', 'sidebar')

    # ã‚¿ãƒ–æ§‹æˆã§ç”»é¢ã‚’æ•´ç†
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰/è§£æ", "ğŸ“‹ ç·¨é›†ï¼ˆæ³¨æ–‡ä¸€è¦§ï¼‰", "ğŸ•˜ å±¥æ­´ï¼ˆDBï¼‰"])
    
    with tab1:
        # æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæœ€ä¸Šæ®µã«ç§»å‹•ï¼‰
        st.subheader("æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®å‰ã«é…ç½®ï¼‰
        if 'data_edited' not in st.session_state:
            st.session_state.data_edited = False
        
        if 'processed_files' not in st.session_state:
            st.session_state.processed_files = set()
        
        if 'parsed_records' not in st.session_state:
            st.session_state.parsed_records = []
        
        # PDFç”»åƒè¡¨ç¤ºè¨­å®šï¼ˆã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’èª¿æ•´ã—ã¦ç¸¦ä½ç½®ã‚’åˆã‚ã›ã‚‹ï¼‰
        col1, col2 = st.columns([4, 1])
        with col1:
            uploaded_files = st.file_uploader(
                label="Infomart / IPORTER / PDF ç­‰ã®æ³¨æ–‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã“ã«ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã¾ãŸã¯é¸æŠã—ã¦ãã ã•ã„",
                accept_multiple_files=True,
                type=['txt', 'csv', 'xlsx', 'pdf'],
                key="file_uploader"
            )
            # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå ´åˆã®ã¿ç·¨é›†çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
            if uploaded_files:
                new_files_count = 0
                for file in uploaded_files:
                    file_hash = f"{file.name}_{file.size}_{file.type}"
                    if file_hash not in st.session_state.processed_files:
                        new_files_count += 1
                
                if new_files_count > 0:
                    st.session_state.data_edited = False
        with col2:
            st.write("")  # ä¸Šéƒ¨ã®ç©ºç™½ã‚’èª¿æ•´
            show_pdf_images = st.checkbox("PDFç”»åƒã‚’è¡¨ç¤º", value=True, help="PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ç”»åƒã‚’è¡¨ç¤ºã™ã‚‹ã‹ã©ã†ã‹ã‚’è¨­å®šã—ã¾ã™")
            
            # è§£ææ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
            if st.button("ğŸ”„ è§£ææ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚»ãƒƒãƒˆ", key="reset_processed_files", help="è§£ææ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™"):
                st.session_state.processed_files = set()
                st.session_state.data_edited = False
                st.session_state.parsed_records = []  # è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚‚ã‚¯ãƒªã‚¢
                st.success("è§£ææ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚")
                st.rerun()

        records = []
        debug_details = []
        
        # LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚¹ã‚³ãƒ¼ãƒ—å¤–ã§ã‚‚ä½¿ç”¨ã™ã‚‹ãŸã‚ã€ã“ã“ã§å®šç¾©ï¼‰
        line_orders = get_line_orders_for_user(username)
        processed_line_orders = [order for order in line_orders if order.get("processed", False)]
        
        # LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºï¼ˆ2ç•ªç›®ã«ç§»å‹•ï¼‰
        st.subheader("ğŸ“± LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿")
        
        # çµ±è¨ˆæƒ…å ±
        if line_orders:
            total_orders = len(line_orders)
            unprocessed_orders = [order for order in line_orders if not order.get("processed", False)]
            processed_orders = [order for order in line_orders if order.get("processed", False)]
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ç·æ³¨æ–‡æ•°", total_orders)
            with col2:
                st.metric("æœªå‡¦ç†", len(unprocessed_orders))
            with col3:
                st.metric("å‡¦ç†æ¸ˆã¿", len(processed_orders))
            with col4:
                st.metric("è§£ææ¸ˆã¿LINEæ³¨æ–‡", len(processed_orders))
        
        # æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ï¼ˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’çµ±ä¸€ï¼‰
        with st.expander("ğŸ“¤ LINEç”»åƒã‚’æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", expanded=True):
            uploaded_line_images = st.file_uploader(
                "LINEã®æ³¨æ–‡ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°é¸æŠå¯èƒ½ï¼‰",
                type=['png', 'jpg', 'jpeg'],
                accept_multiple_files=True,
                key="line_image_upload"
            )
            
            if uploaded_line_images:
                # äºŒé‡ä¿å­˜é˜²æ­¢ç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–
                if "saved_line_images" not in st.session_state:
                    st.session_state.saved_line_images = set()
                
                saved_count = 0
                error_count = 0
                
                for uploaded_line_image in uploaded_line_images:
                    # äºŒé‡ä¿å­˜é˜²æ­¢ç”¨ã®ç°¡æ˜“ã‚­ãƒ¼
                    upkey = f"{uploaded_line_image.name}_{uploaded_line_image.size}"
                    
                    if upkey not in st.session_state.saved_line_images:
                        try:
                            image_bytes = uploaded_line_image.getvalue()  # .read()ã‚ˆã‚Šå®‰å…¨
                            ok, msg = save_line_order_data(
                                username,   # line_accountã¯ãƒ­ã‚°ã‚¤ãƒ³IDã§OK
                                name or "ä¸æ˜",  # é€ä¿¡è€…åã¯ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã‚’æµç”¨
                                image_bytes,
                                ""          # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ä¸è¦
                            )
                            if ok:
                                st.session_state.saved_line_images.add(upkey)
                                saved_count += 1
                            else:
                                st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼ ({uploaded_line_image.name}): {msg}")
                                error_count += 1
                        except Exception as e:
                            st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼ ({uploaded_line_image.name}): {e}")
                            error_count += 1
                
                # ä¿å­˜çµæœã®è¡¨ç¤º
                if saved_count > 0:
                    st.success(f"{saved_count}ä»¶ã®LINEæ³¨æ–‡ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
                    if error_count > 0:
                        st.warning(f"{error_count}ä»¶ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    st.rerun()
                elif error_count > 0:
                    st.error(f"{error_count}ä»¶ã™ã¹ã¦ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                st.subheader("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸLINEç”»åƒ")
                for i, uploaded_line_image in enumerate(uploaded_line_images):
                    st.image(uploaded_line_image, caption=f"ç”»åƒ {i+1}: {uploaded_line_image.name}", width=400)
        
        # æ—¢å­˜ã®LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        if line_orders:
            
            # æœªå‡¦ç†ã®æ³¨æ–‡ã®ã¿ã‚’è¡¨ç¤º
            unprocessed_orders = [order for order in line_orders if not order.get("processed", False)]
            
            if unprocessed_orders:
                st.info(f"æœªå‡¦ç†ã®LINEæ³¨æ–‡ãŒ {len(unprocessed_orders)} ä»¶ã‚ã‚Šã¾ã™ã€‚")
                
                # ä¸€æ‹¬è§£æãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
                col1, col2 = st.columns([1, 1])
                with col1:
                    if st.button("ğŸš€ ä¸€æ‹¬è§£æé–‹å§‹", type="primary", key="batch_parse"):
                        try:
                            with st.spinner(f"{len(unprocessed_orders)}ä»¶ã®LINEæ³¨æ–‡ã‚’ä¸€æ‹¬è§£æä¸­..."):
                                processed_count = 0
                                error_count = 0
                                
                                # å‡¦ç†é †åºã‚’å®‰å®šåŒ–ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é †ï¼‰
                                sorted_orders = sorted(unprocessed_orders, key=lambda x: x['timestamp'])
                                
                                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                                st.info(f"å‡¦ç†å¯¾è±¡: {len(sorted_orders)}ä»¶ã®æ³¨æ–‡")
                                
                                for i, order in enumerate(sorted_orders, 1):
                                    st.info(f"å‡¦ç†ä¸­ ({i}/{len(sorted_orders)}): {order['sender_name']} - {order['timestamp']}")
                                    try:
                                        image_path = os.path.join(LINE_ORDERS_DIR, order['image_filename'])
                                        if os.path.exists(image_path):
                                            # OpenAI APIã§è§£æ
                                            parsed_data = parse_line_order_with_openai(
                                                image_path, 
                                                order['sender_name'], 
                                                order.get('message_text', ''),
                                                order['order_date'] # å—ä¿¡æ—¥æ™‚ã‚’æ¸¡ã™
                                            )
                                            
                                            # è§£æçµæœã‚’ä¿å­˜ï¼ˆprocessedãƒ•ãƒ©ã‚°ã‚‚æ›´æ–°ã•ã‚Œã‚‹ï¼‰
                                            success, message = save_parsed_line_order_data(order['timestamp'], parsed_data)
                                            if success:
                                                processed_count += 1
                                            else:
                                                error_count += 1
                                                st.error(f"è§£æçµæœã®ä¿å­˜ã«å¤±æ•— ({order['sender_name']}): {message}")
                                            
                                        else:
                                            error_count += 1
                                            st.error(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ ({order['sender_name']}): {order['image_filename']}")
                                    except Exception as e:
                                        error_count += 1
                                        st.error(f"è§£æã‚¨ãƒ©ãƒ¼ ({order['sender_name']}): {e}")
                                
                                st.success(f"ä¸€æ‹¬è§£æå®Œäº†ï¼ æˆåŠŸ: {processed_count}ä»¶, ã‚¨ãƒ©ãƒ¼: {error_count}ä»¶")
                                st.rerun()
                        except Exception as e:
                            st.error(f"ä¸€æ‹¬è§£æã‚¨ãƒ©ãƒ¼: {e}")
                
                with col2:
                    if st.button("ğŸ—‘ï¸ æœªå‡¦ç†ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å‰Šé™¤", type="secondary", key="batch_delete"):
                        try:
                            deleted_count = 0
                            for order in unprocessed_orders:
                                success, message = delete_line_order_by_timestamp(order['timestamp'])
                                if success:
                                    deleted_count += 1
                            
                            st.success(f"æœªå‡¦ç†ãƒ‡ãƒ¼ã‚¿ã‚’ {deleted_count} ä»¶å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                            st.rerun()
                        except Exception as e:
                            st.error(f"ä¸€æ‹¬å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
                
                st.markdown("---")
                
                for i, order in enumerate(unprocessed_orders):
                    with st.expander(f"ğŸ“‹ {order['sender_name']} - {order['order_date']} ({order['timestamp']})"):
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            # ç”»åƒã‚’è¡¨ç¤º
                            image_path = os.path.join(LINE_ORDERS_DIR, order['image_filename'])
                            if os.path.exists(image_path):
                                st.image(image_path, caption=f"LINEæ³¨æ–‡ç”»åƒ", width=400)
                            
                            # æ³¨æ–‡æƒ…å ±ã‚’è¡¨ç¤º
                            st.write(f"**é€ä¿¡è€…**: {order['sender_name']}")
                            st.write(f"**å—ä¿¡æ—¥**: {order['order_date']}")
                            if order.get('message_text'):
                                st.write(f"**ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**: {order['message_text']}")
                        
                        with col2:
                            # è§£æãƒœã‚¿ãƒ³
                            if st.button(f"è§£æé–‹å§‹", key=f"parse_{i}_{order['timestamp']}"):
                                try:
                                    with st.spinner("LINEæ³¨æ–‡ã‚’è§£æä¸­..."):
                                        # OpenAI APIã§è§£æ
                                        parsed_data = parse_line_order_with_openai(
                                            image_path, 
                                            order['sender_name'], 
                                            order.get('message_text', ''),
                                            order['order_date'] # å—ä¿¡æ—¥æ™‚ã‚’æ¸¡ã™
                                        )
                                        
                                        # æ¨™æº–å½¢å¼ã«å¤‰æ›
                                        records = []
                                        delivery_date = parsed_data.get("delivery_date", "")
                                        items = parsed_data.get("items", [])
                                        
                                        for item in items:
                                            record = {
                                                "order_id": item.get("order_id", ""),
                                                "order_date": order['order_date'],  # Webã‚¢ãƒ—ãƒªã§ã®å—ä¿¡æ—¥ã‚’ä½¿ç”¨
                                                "delivery_date": delivery_date,
                                                "partner_name": parsed_data.get("partner_name", order['sender_name']),
                                                "product_code": item.get("product_code", ""),
                                                "product_name": item.get("product_name", ""),
                                                "size": item.get("size", ""),
                                                "quantity": item.get("quantity", ""),
                                                "unit": item.get("unit", ""),
                                                "unit_price": item.get("unit_price", ""),
                                                "amount": item.get("amount", ""),
                                                "remark": item.get("remark", ""),
                                                "data_source": f"LINEæ³¨æ–‡_{order['timestamp']}"
                                            }
                                            records.append(record)
                                        
                                        # è§£æçµæœã‚’ä¿å­˜
                                        success, message = save_parsed_line_order_data(order['timestamp'], parsed_data)
                                        if not success:
                                            st.error(f"è§£æçµæœã®ä¿å­˜ã«å¤±æ•—: {message}")
                                        
                                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                                        try:
                                            # æ¨™æº–å½¢å¼ã®DataFrameã‚’ä½œæˆ
                                            df_line = pd.DataFrame(records)
                                            if not df_line.empty:
                                                # åˆ—åã‚’æ—¥æœ¬èªã«å¤‰æ›
                                                df_line.columns = ["ä¼ç¥¨ç•ªå·", "ç™ºæ³¨æ—¥", "ç´å“æ—¥", "å–å¼•å…ˆå", "å•†å“ã‚³ãƒ¼ãƒ‰", "å•†å“å", "ã‚µã‚¤ã‚º", "æ•°é‡", "å˜ä½", "å˜ä¾¡", "é‡‘é¡", "å‚™è€ƒ", "ãƒ‡ãƒ¼ã‚¿å…ƒ"]
                                                # ãƒãƒƒãƒIDã‚’ç”Ÿæˆ
                                                jst = pytz.timezone("Asia/Tokyo")
                                                now_str = datetime.now(jst).strftime("%y%m%d_%H%M")
                                                batch_id = f"LINE_{order['timestamp']}_{now_str}"
                                                
                                                # LINEè§£æçµæœã‚’ç”»é¢è¡¨ç¤ºã®ã¿ï¼ˆDBä¿å­˜ã¯Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ™‚ï¼‰
                                                st.success(f"LINEæ³¨æ–‡è§£æå®Œäº†: {order['sender_name']}")
                                        except Exception as e:
                                            st.error(f"LINEè§£æã‚¨ãƒ©ãƒ¼: {e}")
                                        
                                        st.success("LINEæ³¨æ–‡ã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                                        st.rerun()
                                        
                                except Exception as e:
                                    st.error(f"LINEæ³¨æ–‡è§£æã‚¨ãƒ©ãƒ¼: {e}")
                            
                            # å‰Šé™¤ãƒœã‚¿ãƒ³
                            if st.button(f"å‰Šé™¤", key=f"delete_{i}_{order['timestamp']}"):
                                # æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
                                orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
                                with open(orders_file, "r", encoding="utf-8") as f:
                                    all_orders = json.load(f)
                                
                                all_orders = [o for o in all_orders if o['timestamp'] != order['timestamp']]
                                
                                with open(orders_file, "w", encoding="utf-8") as f:
                                    json.dump(all_orders, f, ensure_ascii=False, indent=4)
                                
                                # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤
                                if os.path.exists(image_path):
                                    os.remove(image_path)
                                
                                st.success("LINEæ³¨æ–‡ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                                st.rerun()
            else:
                st.info("æœªå‡¦ç†ã®LINEæ³¨æ–‡ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.info("LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")
        
        # SMS/ãƒ¡ãƒ¼ãƒ«ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ©Ÿèƒ½ï¼ˆLINEæ³¨æ–‡ç”»é¢ã®ä¸‹ã«è¿½åŠ ï¼‰
        st.markdown("---")
        st.subheader("âœ‰ï¸ SMS/ãƒ¡ãƒ¼ãƒ« ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ï¼ˆä¸‹æ›¸ãä¿å­˜â†’ä¸€æ‹¬è§£æï¼‰")
        
        colL, colR = st.columns([2,1])
        with colL:
            in_customer = st.text_input("é¡§å®¢åï¼ˆå¿…é ˆï¼‰", key="txt_customer")
            in_message  = st.text_area("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ï¼ˆå¿…é ˆï¼‰", height=140, key="txt_message")
        
        with colR:
            use_date = st.checkbox("ç´å“æ—¥ã‚’æŒ‡å®šã™ã‚‹ï¼ˆä»»æ„ï¼‰", value=False)
            if use_date:
                picked = st.date_input("ç´å“æ—¥ï¼ˆä»»æ„ï¼‰", help="ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã¯æœ¬æ—¥ã‚’å«ã‚€æœˆã‹ã‚‰è¡¨ç¤ºã•ã‚Œã¾ã™")
                delivery_opt = picked.strftime("%Y/%m/%d")
            else:
                delivery_opt = ""
        
        # å—ä¿¡æ—¥=ä¿å­˜æ™‚JST
        if st.button("ğŸ’¾ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜", type="secondary", key="btn_text_save"):
            if not in_customer or not in_message:
                st.warning("é¡§å®¢åã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯å¿…é ˆã§ã™")
            else:
                ok, msg, ts = save_text_order_data(username, in_customer, in_message, delivery_opt)
                (st.success if ok else st.error)(msg)
                if ok:
                    # å…¥åŠ›æ¬„ã‚’ã‚¯ãƒªã‚¢ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å‰Šé™¤ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œï¼‰
                    if "txt_customer" in st.session_state:
                        del st.session_state["txt_customer"]
                    if "txt_message" in st.session_state:
                        del st.session_state["txt_message"]
                    st.rerun()
        
        # ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
        text_orders = get_text_orders_for_user(username)
        unproc_texts = [t for t in text_orders if not t.get("processed", False)]
        proc_texts   = [t for t in text_orders if t.get("processed", False)]
        
        st.info(f"æœªå‡¦ç†ãƒ†ã‚­ã‚¹ãƒˆ: {len(unproc_texts)} / è§£ææ¸ˆã¿: {len(proc_texts)}")
        
        if unproc_texts:
            if st.button("ğŸš€ ãƒ†ã‚­ã‚¹ãƒˆä¸€æ‹¬è§£æ", type="primary", key="btn_text_batch"):
                success_cnt = err_cnt = 0
                for t in sorted(unproc_texts, key=lambda x: x["timestamp"]):
                    try:
                        parsed = parse_text_order_with_openai(
                            t["customer_name"], t["message_text"], t["order_date"], t.get("delivery_date_opt","")
                        )
                        ok, _ = save_parsed_text_order_data(t["timestamp"], parsed)
                        success_cnt += 1 if ok else 0
                    except Exception as e:
                        err_cnt += 1
                        st.error(f"è§£æã‚¨ãƒ©ãƒ¼ ({t['customer_name']}): {e}")
                st.success(f"ä¸€æ‹¬è§£æ å®Œäº†ï¼šæˆåŠŸ {success_cnt} / å¤±æ•— {err_cnt}")
                st.rerun()
        
        # æœªå‡¦ç†ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ã®è¡¨ç¤º
        if unproc_texts:
            st.markdown("#### æœªå‡¦ç†ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡")
            with st.expander("ğŸ“‹ æœªå‡¦ç†TEXTæ³¨æ–‡è©³ç´°", expanded=False):
                for i, t in enumerate(unproc_texts):
                    st.write(f"**{i+1}. {t['customer_name']} - {t['order_date']} ({t['timestamp']})**")
                    st.write(f"æœ¬æ–‡: {t['message_text'][:300]}{'...' if len(t['message_text'])>300 else ''}")
                    if t.get('delivery_date_opt'):
                        st.write(f"æŒ‡å®šç´å“æ—¥: {t['delivery_date_opt']}")
                    if st.button("ğŸ—‘ï¸ å‰Šé™¤", key=f"del_unproc_txt_{i}_{t['timestamp']}"):
                        ok, msg = delete_text_order_by_timestamp(t["timestamp"])
                        (st.success if ok else st.error)(msg)
                        st.rerun()
        
        # è§£ææ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ã®è¡¨ç¤º
        if proc_texts:
            st.markdown("#### è§£ææ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡")
            with st.expander("ğŸ“‹ è§£ææ¸ˆã¿TEXTæ³¨æ–‡è©³ç´°", expanded=False):
                for i, t in enumerate(proc_texts):
                    st.write(f"**{i+1}. {t['customer_name']} - {t['order_date']} ({t['timestamp']})**")
                    st.write(f"æœ¬æ–‡: {t['message_text'][:300]}{'...' if len(t['message_text'])>300 else ''}")
                    if t.get('delivery_date_opt'):
                        st.write(f"æŒ‡å®šç´å“æ—¥: {t['delivery_date_opt']}")
                    
                    # è§£æçµæœã®è¡¨ç¤º
                    parsed_data = t.get('parsed_data')
                    if parsed_data:
                        st.write("**è§£æçµæœ:**")
                        if parsed_data.get('delivery_date'):
                            st.write(f"ç´å“æ—¥: {parsed_data['delivery_date']}")
                        items = parsed_data.get('items', [])
                        if items:
                            st.write("**å•†å“ä¸€è¦§:**")
                            for j, item in enumerate(items):
                                st.write(f"  {j+1}. {item.get('product_name', '')} - æ•°é‡: {item.get('quantity', '')} {item.get('unit', '')}")
                                if item.get('remark'):
                                    st.write(f"     å‚™è€ƒ: {item['remark']}")
                    
                    if st.button("ğŸ—‘ï¸ å‰Šé™¤", key=f"del_proc_txt_{i}_{t['timestamp']}"):
                        ok, msg = delete_text_order_by_timestamp(t["timestamp"])
                        (st.success if ok else st.error)(msg)
                        st.rerun()
    
        
        # ç·¨é›†æ¸ˆã¿ã®å ´åˆã¯å†è§£æã‚’ã‚¹ã‚­ãƒƒãƒ—
        if not st.session_state.data_edited:
            # æ—¢å­˜ã®è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            records = st.session_state.parsed_records.copy()
            
            # å…¨ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºæ©Ÿèƒ½ã‚’è¿½åŠ 
            if processed_line_orders:
                
                
                # è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°è¡¨ç¤ºï¼ˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’çµ±ä¸€ï¼‰
                with st.expander("ğŸ“‹ è§£ææ¸ˆã¿LINEæ³¨æ–‡è©³ç´°", expanded=False):
                    for i, order in enumerate(processed_line_orders):
                        col1, col2 = st.columns([3, 1])
                        
                        with col1:
                            st.write(f"**{i+1}. {order['sender_name']} - {order['order_date']}**")
                            st.write(f"å—ä¿¡æ—¥æ™‚: {order['timestamp']}")
                            if order.get('message_text'):
                                st.write(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {order['message_text']}")
                        
                        with col2:
                            st.write("")  # ä¸Šéƒ¨ã®ç©ºç™½ã‚’èª¿æ•´
                            # ç”»åƒè¡¨ç¤º
                            image_path = os.path.join(LINE_ORDERS_DIR, order['image_filename'])
                            if os.path.exists(image_path):
                                st.image(image_path, caption="LINEæ³¨æ–‡ç”»åƒ", width=200)
                        
                        st.markdown("---")
            
            # LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’recordsã«è¿½åŠ ï¼ˆã¾ã è¿½åŠ ã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ï¼‰
            existing_line_sources = {record.get("data_source", "") for record in records}
            for order in processed_line_orders:
                line_source = f"LINEæ³¨æ–‡_{order['timestamp']}"
                if line_source not in existing_line_sources:
                    # å‡¦ç†æ¸ˆã¿ã®LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’recordsã«è¿½åŠ 
                    st.info(f"å‡¦ç†æ¸ˆã¿LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿: {order['sender_name']} - {order['order_date']}")
                    
                    # ä¿å­˜ã•ã‚ŒãŸè§£æçµæœã‚’å–å¾—
                    parsed_data = order.get('parsed_data')
                    if parsed_data:
                        # è§£æçµæœã‹ã‚‰å•†å“æƒ…å ±ã‚’å–å¾—
                        delivery_date = parsed_data.get("delivery_date", order['order_date'])
                        items = parsed_data.get("items", [])
                        
                        for item in items:
                            record = {
                                "order_id": f"LINE_{order['timestamp']}",
                                "order_date": order['order_date'],
                                "delivery_date": delivery_date,
                                "partner_name": parsed_data.get("partner_name", order['sender_name']),
                                "product_code": item.get("product_code", ""),
                                "product_name": item.get("product_name", ""),
                                "size": item.get("size", ""),
                                "quantity": item.get("quantity", ""),
                                "unit": item.get("unit", ""),
                                "unit_price": item.get("unit_price", ""),
                                "amount": item.get("amount", ""),
                                "remark": item.get("remark", ""),
                                "data_source": line_source
                            }
                            records.append(record)
                    else:
                        # è§£æçµæœãŒãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                        record = {
                            "order_id": f"LINE_{order['timestamp']}",
                            "order_date": order['order_date'],
                            "delivery_date": order['order_date'],
                            "partner_name": order['sender_name'],
                            "product_code": "",
                            "product_name": "LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ï¼ˆè§£æçµæœãªã—ï¼‰",
                            "size": "",
                            "quantity": "",
                            "unit": "",
                            "unit_price": "",
                            "amount": "",
                            "remark": f"LINEæ³¨æ–‡ - {order['timestamp']}",
                            "data_source": line_source
                        }
                        records.append(record)
            
            # ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’recordsã«è¿½åŠ ï¼ˆã¾ã è¿½åŠ ã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ï¼‰
            processed_text_orders = [t for t in text_orders if t.get("processed", False)]
            existing_sources = {r.get("data_source","") for r in records}
            for t in processed_text_orders:
                src = f"TEXTæ³¨æ–‡_{t['timestamp']}"
                if src in existing_sources:
                    continue
                parsed = t.get("parsed_data") or {}
                delivery = parsed.get("delivery_date") or t.get("delivery_date_opt") or t["order_date"]
                partner  = parsed.get("partner_name") or t["customer_name"]
                items = parsed.get("items", [])
                if not items:
                    # è§£æå¤±æ•—ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    records.append({
                        "order_id": f"TEXT_{t['timestamp']}",
                        "order_date": t["order_date"],
                        "delivery_date": delivery,
                        "partner_name": partner,
                        "product_code": "",
                        "product_name": "ãƒ†ã‚­ã‚¹ãƒˆæ³¨æ–‡ï¼ˆè§£æçµæœãªã—ï¼‰",
                        "size": "",
                        "quantity": "",
                        "unit": "",
                        "unit_price": "",
                        "amount": "",
                        "remark": f"TEXTæ³¨æ–‡ - {t['timestamp']}",
                        "data_source": src
                    })
                else:
                    for it in items:
                        records.append({
                            "order_id": parsed.get("order_id","") or f"TEXT_{t['timestamp']}",
                            "order_date": t["order_date"],
                            "delivery_date": delivery,
                            "partner_name": partner,
                            "product_code": it.get("product_code",""),
                            "product_name": it.get("product_name",""),
                            "size": it.get("size",""),
                            "quantity": it.get("quantity",""),
                            "unit": it.get("unit",""),
                            "unit_price": it.get("unit_price",""),
                            "amount": it.get("amount",""),
                            "remark": it.get("remark",""),
                            "data_source": src
                        })
            
            if uploaded_files:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ã¨å¤šé‡è§£æé˜²æ­¢
                new_files = []
                for file in uploaded_files:
                    file_hash = f"{file.name}_{file.size}_{file.type}"
                    if file_hash in st.session_state.processed_files:
                        st.info(f"{file.name} ã¯æ—¢ã«è§£ææ¸ˆã¿ã§ã™ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
                        continue
                    new_files.append(file)
                
                if new_files:
                    st.info(f"æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ« {len(new_files)} ä»¶ã‚’è§£æã—ã¾ã™")
                    
                    for file in new_files:
                        filename = file.name
                        content = file.read()

                        if filename.lower().endswith((".txt", ".csv")):
                            filetype, detected_enc, debug_log = detect_csv_type(content)
                            debug_details.append(f"ã€{filename}ã€‘\n" + "\n".join(debug_log))
                            file_like = io.BytesIO(content)
                            if filetype == 'infomart':
                                records += parse_infomart(file_like, filename)
                                st.success(f"{filename} ã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸ")
                                # è§£ææˆåŠŸã®æœ«å°¾ã§å¿…ãšç™»éŒ²
                                file_hash = f"{file.name}_{file.size}_{file.type}"
                                st.session_state.processed_files.add(file_hash)
                            elif filetype == 'iporter':
                                records += parse_iporter(file_like, filename)
                                st.success(f"{filename} ã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸ")
                                # è§£ææˆåŠŸã®æœ«å°¾ã§å¿…ãšç™»éŒ²
                                file_hash = f"{file.name}_{file.size}_{file.type}"
                                st.session_state.processed_files.add(file_hash)
                            else:
                                st.warning(f"{filename} ã¯æœªå¯¾å¿œã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã™")

                        elif filename.lower().endswith(".xlsx"):
                            try:
                                df_excel = pd.read_excel(io.BytesIO(content), sheet_name=0, header=None)
                                if df_excel.shape[0] > 5 and str(df_excel.iloc[4, 1]).strip() == "ä¼ç¥¨ç•ªå·":
                                    file_like = io.BytesIO(content)
                                    try:
                                        mitsubishi_records = parse_mitsubishi(file_like, filename)
                                        records += mitsubishi_records
                                        st.success(f"{filename} ã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸ")
                                        
                                        # è§£ææˆåŠŸã®æœ«å°¾ã§å¿…ãšç™»éŒ²
                                        file_hash = f"{file.name}_{file.size}_{file.type}"
                                        st.session_state.processed_files.add(file_hash)
                                    except Exception as parse_error:
                                        st.error(f"{filename} ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {parse_error}")
                                        # ãƒ­ã‚°ã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—
                                        import logging
                                        logger = logging.getLogger('parser_mitsubishi')
                                        if logger.handlers:
                                            for handler in logger.handlers:
                                                if hasattr(handler, 'baseFilename'):
                                                    st.info(f"è©³ç´°ãƒ­ã‚°: {handler.baseFilename}")
                                else:
                                    st.warning(f"{filename} ã¯æœªå¯¾å¿œã®Excelãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã™")
                            except Exception as e:
                                st.error(f"{filename} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                        
                        elif filename.lower().endswith(".pdf"):
                            # PDFç”»åƒã®æŠ½å‡ºã¨è¡¨ç¤º
                            if show_pdf_images:
                                pdf_images = extract_pdf_images(content)
                                if pdf_images:
                                    display_pdf_images(pdf_images, filename)
                            
                            # PDFè§£æã®å®Ÿè¡Œ
                            try:
                                with st.spinner(f"{filename} ã‚’è§£æä¸­..."):
                                    # APIã‚­ãƒ¼ã®äº‹å‰ç¢ºèª
                                    try:
                                        from config import get_openai_api_key
                                        api_key = get_openai_api_key()
                                        if not api_key:
                                            st.error("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                                            continue
                                    except Exception as api_error:
                                        st.error(f"APIã‚­ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {api_error}")
                                        continue
                                    
                                    pdf_records = parse_pdf_handwritten(content, filename)
                                    records += pdf_records
                                    # å•†å“æƒ…å ±ã®æŠ½å‡ºçŠ¶æ³ã‚’ç¢ºèª
                                    if pdf_records and pdf_records[0].get('product_name') == "å•†å“æƒ…å ±ãªã—":
                                        st.warning("å•†å“æƒ…å ±ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹æ›¸ãæ–‡å­—ã®èªè­˜ç²¾åº¦ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                                st.success(f"{filename} ã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸ")
                                
                                # è§£ææˆåŠŸã®æœ«å°¾ã§å¿…ãšç™»éŒ²
                                file_hash = f"{file.name}_{file.size}_{file.type}"
                                st.session_state.processed_files.add(file_hash)
                            except Exception as e:
                                st.error(f"{filename} ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                                st.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {str(e)}")
                                # æœ¬ç•ªç’°å¢ƒã§ã®è¿½åŠ æƒ…å ±
                                if is_production():
                                    st.info("æœ¬ç•ªç’°å¢ƒã§ã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:")
                                    st.info("1. Render Secrets Filesã§OPENAI_API_KEYãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª")
                                    st.info("2. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¦ç’°å¢ƒå¤‰æ•°ã‚’åæ˜ ")
                                    st.info("3. Renderã®ãƒ­ã‚°ã§è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ç¢ºèª")
                else:
                    st.info("ğŸ“ ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«è§£ææ¸ˆã¿ã§ã™ã€‚æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            
            # è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            st.session_state.parsed_records = records
        else:
            # ç·¨é›†æ¸ˆã¿ã®å ´åˆã¯æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
            st.info("ğŸ“ ãƒ‡ãƒ¼ã‚¿ãŒç·¨é›†ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨å†è§£æã•ã‚Œã¾ã™ã€‚")
            if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’å†èª­ã¿è¾¼ã¿", key="reload_data"):
                st.session_state.data_edited = False
                st.rerun()
            # ç·¨é›†æ¸ˆã¿ã®å ´åˆã‚‚æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            records = st.session_state.parsed_records.copy()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã¯è‡ªå‹•DBä¿å­˜ã—ãªã„ï¼ˆExcelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ™‚ã«ä¿å­˜ï¼‰
        # ãƒ‡ãƒ¼ã‚¿ã¯ç”»é¢è¡¨ç¤ºã®ã¿ã§ã€DBä¿å­˜ã¯æ˜ç¤ºçš„ãªæ“ä½œï¼ˆExcelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰æ™‚ã®ã¿å®Ÿè¡Œ

    with tab2:
        # ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼ˆç©ºã§ã‚‚è¡¨ç¤ºï¼‰
        if records:        
            df = pd.DataFrame(records)
            
            # ç©ºè¡Œé™¤å¤–ã®æ¡ä»¶ã‚’ç·©å’Œï¼ˆå•†å“åã¾ãŸã¯å‚™è€ƒã«å€¤ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤ºï¼‰
            if not df.empty:
                # å•†å“åã¾ãŸã¯å‚™è€ƒã«å€¤ãŒã‚ã‚‹è¡Œã®ã¿ã‚’ä¿æŒ
                df = df[df['product_name'].notna() | df['remark'].notna()]
            
            if not df.empty:
                columns = [
                    "order_id", "order_date", "delivery_date", "partner_name",
                    "product_code", "product_name", "size", "quantity", "unit", "unit_price", "amount", "remark", "data_source"
                ]
                df = df.reindex(columns=columns)
                df.columns = ["ä¼ç¥¨ç•ªå·", "ç™ºæ³¨æ—¥", "ç´å“æ—¥", "å–å¼•å…ˆå", "å•†å“ã‚³ãƒ¼ãƒ‰", "å•†å“å", "ã‚µã‚¤ã‚º", "æ•°é‡", "å˜ä½", "å˜ä¾¡", "é‡‘é¡", "å‚™è€ƒ", "ãƒ‡ãƒ¼ã‚¿å…ƒ"]
                
                # é‡è¤‡è¡Œã®é™¤å»
                df = df.drop_duplicates(
                    subset=["ä¼ç¥¨ç•ªå·","ç™ºæ³¨æ—¥","ç´å“æ—¥","å–å¼•å…ˆå","å•†å“ã‚³ãƒ¼ãƒ‰","å•†å“å","ã‚µã‚¤ã‚º","æ•°é‡","å˜ä½","å˜ä¾¡","é‡‘é¡","å‚™è€ƒ","ãƒ‡ãƒ¼ã‚¿å…ƒ"],
                    keep="first"
                )

                edited_df = st.data_editor(
                    df,
                    use_container_width=True,
                    num_rows="dynamic",
                    key="editor",
                    hide_index=True,
                    on_change=lambda: setattr(st.session_state, 'data_edited', True)
                )
            else:
                st.warning("è¡¨ç¤ºå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å•†å“æƒ…å ±ã®æŠ½å‡ºã«å¤±æ•—ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

            for col in ["ç™ºæ³¨æ—¥", "ç´å“æ—¥"]:
                edited_df[col] = pd.to_datetime(edited_df[col], errors="coerce").dt.strftime("%Y/%m/%d")

            edited_df["æ•°é‡"] = pd.to_numeric(edited_df["æ•°é‡"], errors="coerce").fillna(0)

            df_sorted = edited_df.sort_values(
                by=["å•†å“å", "ç´å“æ—¥", "ç™ºæ³¨æ—¥"], na_position="last"
            )

            df_agg = (
                df_sorted
                .groupby(["å•†å“å", "ã‚µã‚¤ã‚º", "å‚™è€ƒ", "å˜ä½"], dropna=False, as_index=False)
                .agg({"æ•°é‡": "sum"})
            )
            df_agg = df_agg[["å•†å“å", "ã‚µã‚¤ã‚º", "å‚™è€ƒ", "æ•°é‡", "å˜ä½"]]
            df_agg = df_agg.sort_values(by=["å•†å“å"])
            output = io.BytesIO()
            jst = pytz.timezone("Asia/Tokyo")
            now_str = datetime.now(jst).strftime("%y%m%d_%H%M")

            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                workbook = writer.book
                header_format = workbook.add_format({'bold': False, 'border': 0})
                
                # ç½«ç·šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆè–„ã„é»’ RGB:50,50,50ï¼‰
                border_format = workbook.add_format({
                    'border': 1,
                    'border_color': '#323232'  # RGB(50,50,50)ã‚’16é€²æ•°ã§
                })

                # â–¼ æ³¨æ–‡ä¸€è¦§ã‚·ãƒ¼ãƒˆ
                sheet1 = "æ³¨æ–‡ä¸€è¦§"
                edited_df.to_excel(writer, index=False, sheet_name=sheet1, startrow=1, header=False)
                worksheet1 = writer.sheets[sheet1]
                for col_num, value in enumerate(edited_df.columns.values):
                    worksheet1.write(0, col_num, value, header_format)

                # â–¼ æ³¨æ–‡ä¸€è¦§(å±¤åˆ¥çµæœ)ã‚·ãƒ¼ãƒˆ
                sheet2 = "æ³¨æ–‡ä¸€è¦§(å±¤åˆ¥çµæœ)"
                df_sorted.to_excel(writer, index=False, sheet_name=sheet2, startrow=1, header=False)
                worksheet2 = writer.sheets[sheet2]
                for col_num, value in enumerate(df_sorted.columns.values):
                    worksheet2.write(0, col_num, value, header_format)

                # â–¼ é›†è¨ˆçµæœã‚·ãƒ¼ãƒˆ
                sheet3 = "é›†è¨ˆçµæœ"
                df_agg.to_excel(writer, index=False, sheet_name=sheet3, startrow=1, header=False)
                worksheet3 = writer.sheets[sheet3]
                for col_num, value in enumerate(df_agg.columns.values):
                    worksheet3.write(0, col_num, value, header_format)

                # ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼šåˆ—åã‹ã‚‰ãƒ”ã‚¯ã‚»ãƒ«ã§å¹…ã‚’è¨­å®šï¼ˆå¤ã„XlsxWriterãªã‚‰æ–‡å­—å¹…æ›ç®—ï¼‰
                def _set_px(ws, name_to_idx: dict, col_label: str, px: int):
                    if col_label not in name_to_idx:
                        return
                    c = name_to_idx[col_label]
                    try:
                        ws.set_column_pixels(c, c, px)        # ã´ã£ãŸã‚Šãƒ”ã‚¯ã‚»ãƒ«æŒ‡å®šï¼ˆæ¨å¥¨ï¼‰
                    except AttributeError:
                        ws.set_column(c, c, round((px - 5) / 7, 2))  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ¦‚ç®—ï¼ˆpxâ†’æ–‡å­—å¹…ï¼‰

                # ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼šè¡¨å…¨ä½“ã«ç½«ç·šã‚’é©ç”¨
                def _apply_borders(ws, df, start_row=0):
                    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç¯„å›²ã«ç½«ç·šã‚’é©ç”¨"""
                    if df.empty:
                        return
                    # ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²ã‚’å–å¾—ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ + ãƒ‡ãƒ¼ã‚¿è¡Œï¼‰
                    end_row = start_row + len(df)
                    end_col = len(df.columns) - 1
                    # ç½«ç·šã‚’é©ç”¨
                    ws.conditional_format(start_row, 0, end_row, end_col, {
                        'type': 'cell',
                        'criteria': '>=',
                        'value': 0,
                        'format': border_format
                    })

                # === åˆ—å¹…è¨­å®š ===
                # æ³¨æ–‡ä¸€è¦§
                cols1 = list(edited_df.columns)
                idx1  = {v: i for i, v in enumerate(cols1)}
                _set_px(worksheet1, idx1, "ç™ºæ³¨æ—¥", 105)
                _set_px(worksheet1, idx1, "ç´å“æ—¥", 105)
                _set_px(worksheet1, idx1, "å•†å“å", 244)
                _set_px(worksheet1, idx1, "å‚™è€ƒ",   244)

                # æ³¨æ–‡ä¸€è¦§(å±¤åˆ¥çµæœ)
                cols2 = list(df_sorted.columns)
                idx2  = {v: i for i, v in enumerate(cols2)}
                _set_px(worksheet2, idx2, "ç™ºæ³¨æ—¥", 105)
                _set_px(worksheet2, idx2, "ç´å“æ—¥", 105)
                _set_px(worksheet2, idx2, "å•†å“å", 244)
                _set_px(worksheet2, idx2, "å‚™è€ƒ",   244)

                # é›†è¨ˆçµæœï¼ˆã“ã®ã‚·ãƒ¼ãƒˆã¯ ç™ºæ³¨æ—¥/ç´å“æ—¥ ãŒç„¡ã„æƒ³å®šï¼‰
                cols3 = list(df_agg.columns)
                idx3  = {v: i for i, v in enumerate(cols3)}
                _set_px(worksheet3, idx3, "å•†å“å", 244)
                _set_px(worksheet3, idx3, "å‚™è€ƒ",   244)

                # === ç½«ç·šé©ç”¨ ===
                _apply_borders(worksheet1, edited_df, 0)    # æ³¨æ–‡ä¸€è¦§
                _apply_borders(worksheet2, df_sorted, 0)    # æ³¨æ–‡ä¸€è¦§(å±¤åˆ¥çµæœ)
                _apply_borders(worksheet3, df_agg, 0)       # é›†è¨ˆçµæœ

                # === å°åˆ·è¨­å®šï¼ˆæ¨ª1ãƒšãƒ¼ã‚¸ã«åã‚ã‚‹ï¼‰ ===
                for ws in (worksheet1, worksheet2, worksheet3):
                    ws.set_landscape()     # æ¨ªå‘ã
                    ws.set_paper(9)        # A4
                    ws.fit_to_pages(1, 0)  # æ¨ª1ãƒšãƒ¼ã‚¸ãƒ»ç¸¦ã¯è‡ªå‹•ç¸®å°ã§å¯å¤‰ï¼ˆ=0ï¼‰
                    ws.set_margins(left=0.3, right=0.3, top=0.5, bottom=0.5)
                    ws.repeat_rows(0, 0)   # 1è¡Œç›®ï¼ˆè¦‹å‡ºã—ï¼‰ã‚’å„ãƒšãƒ¼ã‚¸ã«ç¹°ã‚Šè¿”ã—

            output.seek(0)
            
            # ç·¨é›†ã‚¿ãƒ–ã§Excelå‡ºåŠ›æ™‚ã«DBä¿å­˜ï¼ˆExcelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®ã¿ï¼‰
            # æ³¨æ„: ã“ã®éƒ¨åˆ†ã¯Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯æ™‚ã«ã®ã¿å®Ÿè¡Œã•ã‚Œã‚‹
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã¨å‰Šé™¤ãƒœã‚¿ãƒ³ã‚’æ¨ªã«ä¸¦ã¹ã‚‹
            col1, col2 = st.columns([3, 1])
            
            with col1:
                downloaded = st.download_button(
                    label="Excelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=output,
                    file_name=f"{now_str}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="download_excel_btn"
                )
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ™‚ã«DBã«ä¿å­˜ï¼ˆå±¥æ­´DBã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼‰
                if downloaded:
                    try:
                        save_order_lines(edited_df, now_str, note="ç·¨é›†ã‚¿ãƒ–ã‹ã‚‰ä¿å­˜ï¼ˆExcelåŒæ™‚ï¼‰")
                        st.success(f"DBã«ä¿å­˜ã—ã¾ã—ãŸï¼ˆãƒãƒƒãƒID: {now_str}ï¼‰")

                        # --- ç”»é¢å´ã®ãƒ‡ãƒ¼ã‚¿ã‚’å®Œå…¨åˆæœŸåŒ– ---
                        st.session_state.parsed_records = []
                        st.session_state.data_edited = False
                        st.session_state.processed_files = set()
                        st.session_state.pop("editor", None)   # Data Editorã®ä¿æŒå€¤ã‚’ç ´æ£„

                        st.rerun()  # â† ã“ã‚ŒãŒç„¡ã„ã¨åŒä¸€è¡¨ç¤ºãŒæ®‹ã£ã¦è¦‹ãˆã‚‹
                    except Exception as e:
                        st.error(f"DBä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                
                # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢ãƒ•ãƒ©ã‚°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®å‡¦ç†
                if st.session_state.get('data_clear_requested', False):
                    try:
                        # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
                        st.session_state.parsed_records = []
                        st.session_state.data_edited = False
                        
                        # è§£ææ¸ˆã¿LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å‰Šé™¤ï¼ˆæœªè§£æãƒ‡ãƒ¼ã‚¿ã¯ä¿æŒï¼‰
                        try:
                            success, message = delete_processed_line_orders()
                            if success:
                                st.info(f"LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿: {message}")
                            else:
                                st.warning(f"LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {message}")
                        except Exception as e:
                            st.warning(f"LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
                        
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®processed_line_ordersã‹ã‚‰è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å‰Šé™¤
                        if 'processed_line_orders' in st.session_state:
                            # è§£ææ¸ˆã¿ã§ãªã„ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä¿æŒ
                            st.session_state.processed_line_orders = [
                                order for order in st.session_state.processed_line_orders 
                                if not order.get("processed", False)
                            ]
                        
                        st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                        
                        # ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
                        st.session_state.data_clear_requested = False
                        
                    except Exception as e:
                        st.error(f"ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")
                        st.session_state.data_clear_requested = False
            
            with col2:
                # è¿½åŠ ï¼šã‚¿ãƒ–2ã®å‰Šé™¤ãƒœã‚¿ãƒ³ã®ç›´å‰ã‚ãŸã‚Šã§æœ€æ–°çŠ¶æ…‹ã‚’å–å¾—ã—ã¦åˆ¤å®š
                line_orders_now = get_line_orders_for_user(username)
                processed_line_orders_now = [o for o in line_orders_now if o.get("processed", False)]
                has_processed_data = bool(processed_line_orders_now or st.session_state.parsed_records)
                
                # å¸¸æ™‚ãƒœã‚¿ãƒ³è¡¨ç¤ºï¼ˆãƒ‡ãƒ¼ã‚¿ãŒç„¡ã‘ã‚Œã°disabledï¼‰
                if st.button("ğŸ—‘ï¸ å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿å‰Šé™¤", type="secondary", disabled=not has_processed_data, key="btn_delete_processed"):
                    try:
                        # LINEå‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å‰Šé™¤
                        if processed_line_orders_now:
                            success, message = delete_processed_line_orders()
                            (st.success if success else st.error)(message)

                        # ç”»é¢ãƒ»ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚‚å®Œå…¨åˆæœŸåŒ–
                        st.session_state.parsed_records = []
                        st.session_state.data_edited = False
                        if 'processed_files' in st.session_state:
                            st.session_state.processed_files.clear()
                        st.session_state.pop("editor", None)   # â† ã“ã“ãŒé‡è¦

                        st.success("âœ… ã™ã¹ã¦ã®å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                        st.rerun()
                    except Exception as e:
                        st.error(f"ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.info("æ³¨æ–‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    
    with tab3:
        st.subheader("ğŸ•˜ ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿å±¥æ­´")
        
        # --- å‰Šé™¤ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ ---
        if "pending_delete_ids" not in st.session_state:
            st.session_state.pending_delete_ids = []
        if "confirm_delete_rows" not in st.session_state:
            st.session_state.confirm_delete_rows = False

        if "pending_delete_batch" not in st.session_state:
            st.session_state.pending_delete_batch = None
        if "confirm_delete_batch" not in st.session_state:
            st.session_state.confirm_delete_batch = False
        
        # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆãƒ‡ãƒ¼ã‚¿ç©ã¿ä¸Šã’æ–¹å¼ï¼‰
        init_db()
        with _conn() as c:
            cur = c.execute("""
            SELECT id, order_id as 'ä¼ç¥¨ç•ªå·', order_date as 'ç™ºæ³¨æ—¥', delivery_date as 'ç´å“æ—¥', partner_name as 'å–å¼•å…ˆå',
                   product_code as 'å•†å“ã‚³ãƒ¼ãƒ‰', product_name as 'å•†å“å', quantity as 'æ•°é‡', unit as 'å˜ä½',
                   unit_price as 'å˜ä¾¡', amount as 'é‡‘é¡', remark as 'å‚™è€ƒ', data_source as 'ãƒ‡ãƒ¼ã‚¿å…ƒ',
                   batch_id as 'ãƒãƒƒãƒID', created_at as 'ç™»éŒ²æ—¥æ™‚'
            FROM order_lines
            ORDER BY created_at DESC
            """)
            rows = cur.fetchall()
            cols = [d[0] for d in cur.description]
        
        if not rows:
            st.info("ä¿å­˜æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            df_all = pd.DataFrame(rows, columns=cols)
            
            # çµ±è¨ˆæƒ…å ±
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ç·ãƒ‡ãƒ¼ã‚¿è¡Œæ•°", len(df_all))
            with col2:
                unique_batches = df_all['ãƒãƒƒãƒID'].nunique()
                st.metric("ç·ãƒãƒƒãƒæ•°", unique_batches)
            with col3:
                latest_date = df_all['ç™»éŒ²æ—¥æ™‚'].iloc[0] if not df_all.empty else "ãªã—"
                st.metric("æœ€æ–°ç™»éŒ²", latest_date)
            
            # ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºï¼ˆç·¨é›†ä¸å¯ã€IDåˆ—ã¯éè¡¨ç¤ºï¼‰
            df_display = df_all.drop('id', axis=1)  # IDåˆ—ã‚’éè¡¨ç¤º
            st.dataframe(df_display, use_container_width=True, hide_index=True)

            # è¡Œå‰Šé™¤æ©Ÿèƒ½
            st.subheader("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿å‰Šé™¤")
            
            # å‰Šé™¤ã™ã‚‹è¡Œã®é¸æŠï¼ˆé€£ç•ªè¡¨ç¤ºï¼‰
            if not df_all.empty:
                # é€£ç•ªã§è¡¨ç¤ºã™ã‚‹ãŸã‚ã®format_func
                def format_row_option(row_id):
                    try:
                        row_data = df_all[df_all['id'] == row_id]
                        if not row_data.empty:
                            product_name = str(row_data['å•†å“å'].iloc[0]) if pd.notna(row_data['å•†å“å'].iloc[0]) else "å•†å“åãªã—"
                            partner_name = str(row_data['å–å¼•å…ˆå'].iloc[0]) if pd.notna(row_data['å–å¼•å…ˆå'].iloc[0]) else "å–å¼•å…ˆåãªã—"
                            batch_id = str(row_data['ãƒãƒƒãƒID'].iloc[0]) if pd.notna(row_data['ãƒãƒƒãƒID'].iloc[0]) else "ãƒãƒƒãƒIDãªã—"
                            # é€£ç•ªã‚’å–å¾—ï¼ˆIDã®é †åºã§é€£ç•ªã‚’ä»˜ä¸ï¼‰
                            row_index = df_all[df_all['id'] == row_id].index[0] + 1
                            return f"{batch_id}_{row_index}: {product_name} - {partner_name}"
                        else:
                            return f"ID {row_id}: ãƒ‡ãƒ¼ã‚¿ãªã—"
                    except Exception:
                        return f"ID {row_id}: ã‚¨ãƒ©ãƒ¼"
                
                selected_ids = st.multiselect(
                    "å‰Šé™¤ã™ã‚‹è¡Œã‚’é¸æŠ",
                    options=df_all['id'].tolist(),
                    format_func=format_row_option,
                    help="å‰Šé™¤ã—ãŸã„è¡Œã®IDã‚’é¸æŠã—ã¦ãã ã•ã„",
                    key="row_delete_picker"
                )
            else:
                selected_ids = []
                st.info("å‰Šé™¤å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

            st.write(f"é¸æŠä¸­: {len(selected_ids)} è¡Œ")

            # 1å›ç›®: å‰Šé™¤å¯¾è±¡ã‚’ä¿å­˜ã—ã¦rerun
            if st.button("é¸æŠã—ãŸè¡Œã‚’å‰Šé™¤", type="secondary", disabled=len(selected_ids)==0):
                st.session_state.pending_delete_ids = selected_ids.copy()
                st.session_state.confirm_delete_rows = True
                st.rerun()

            # 2å›ç›®: ç¢ºèªãƒ•ã‚§ãƒ¼ã‚ºã‚’è¡¨ç¤º
            if st.session_state.confirm_delete_rows:
                ids = st.session_state.pending_delete_ids
                # é»„è‰²æ ã®å¹…ã‚’ç‹­ã‚ã‚‹
                col_warning, col_empty = st.columns([2, 1])
                with col_warning:
                    st.warning(f"âš ï¸ {len(ids)} è¡Œã‚’å‰Šé™¤ã—ã¾ã™ã€‚ã“ã®æ“ä½œã¯å–ã‚Šæ¶ˆã›ã¾ã›ã‚“ã€‚")
                
                # ãƒœã‚¿ãƒ³ã‚’ç¸¦ä¸¦ã³ã«é…ç½®
                if st.button("ç¢ºèªã—ã¦å‰Šé™¤", type="primary", key="confirm_delete_rows_go"):
                    try:
                        deleted_count = 0
                        with _conn() as c:
                            c.executemany("DELETE FROM order_lines WHERE id = ?", [(i,) for i in ids])
                            deleted_count = c.execute("SELECT changes()").fetchone()[0]  # sqliteã®å¤‰æ›´ä»¶æ•°ç¢ºèª
                        st.success(f"âœ… {deleted_count} è¡Œã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                    except Exception as e:
                        st.error(f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
                    finally:
                        st.session_state.confirm_delete_rows = False
                        st.session_state.pending_delete_ids = []
                        st.rerun()
                
                if st.button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«", key="cancel_delete_rows"):
                    st.session_state.confirm_delete_rows = False
                    st.session_state.pending_delete_ids = []
                    st.info("å‰Šé™¤ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            
            # ãƒãƒƒãƒå˜ä½ã§ã®å‰Šé™¤
            st.subheader("ğŸ—‘ï¸ ãƒãƒƒãƒå˜ä½å‰Šé™¤")
            
            # ãƒãƒƒãƒé¸æŠï¼ˆé€£ç•ªè¡¨ç¤ºï¼‰
            unique_batches = df_all['ãƒãƒƒãƒID'].unique()
            if len(unique_batches) > 0:
                # é€£ç•ªã§è¡¨ç¤ºã™ã‚‹ãŸã‚ã®format_func
                def format_batch_option(batch_id):
                    row_count = len(df_all[df_all['ãƒãƒƒãƒID'] == batch_id])
                    # ãƒãƒƒãƒã®é †åºã§é€£ç•ªã‚’ä»˜ä¸
                    batch_index = list(unique_batches).index(batch_id) + 1
                    return f"{batch_id}_{batch_index}ï¼ˆ{row_count}è¡Œï¼‰"
                
                selected_batch = st.selectbox(
                    "å‰Šé™¤ã™ã‚‹ãƒãƒƒãƒã‚’é¸æŠ",
                    options=unique_batches,
                    format_func=format_batch_option,
                    key="batch_delete_picker"
                )

                st.info(f"é¸æŠã•ã‚ŒãŸãƒãƒƒãƒ: {selected_batch}")
                
                if st.button("é¸æŠã—ãŸãƒãƒƒãƒã‚’å‰Šé™¤", type="secondary", disabled=selected_batch is None):
                    st.session_state.pending_delete_batch = selected_batch
                    st.session_state.confirm_delete_batch = True
                    st.rerun()

                # ç¢ºèªãƒ•ã‚§ãƒ¼ã‚º
                if st.session_state.confirm_delete_batch:
                    b = st.session_state.pending_delete_batch
                    cnt = len(df_all[df_all['ãƒãƒƒãƒID'] == b])
                    # é»„è‰²æ ã®å¹…ã‚’ç‹­ã‚ã‚‹
                    col_warning, col_empty = st.columns([2, 1])
                    with col_warning:
                        st.warning(f"âš ï¸ ãƒãƒƒãƒ '{b}' ã® {cnt} è¡Œã‚’å‰Šé™¤ã—ã¾ã™ã€‚å–ã‚Šæ¶ˆã›ã¾ã›ã‚“ã€‚")
                    
                    # ãƒœã‚¿ãƒ³ã‚’ç¸¦ä¸¦ã³ã«é…ç½®
                    if st.button("ç¢ºèªã—ã¦ãƒãƒƒãƒå‰Šé™¤", type="primary", key="confirm_delete_batch_go"):
                        try:
                            with _conn() as c:
                                c.execute("DELETE FROM order_lines WHERE batch_id = ?", (b,))
                                c.execute("DELETE FROM batches WHERE batch_id = ?", (b,))
                                # å¿µã®ãŸã‚ä»¶æ•°ãƒã‚§ãƒƒã‚¯
                                remain = c.execute("SELECT COUNT(*) FROM order_lines WHERE batch_id = ?", (b,)).fetchone()[0]
                            st.success(f"âœ… ãƒãƒƒãƒ '{b}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸï¼ˆ{cnt}â†’æ®‹{remain}è¡Œï¼‰")
                        except Exception as e:
                            st.error(f"ãƒãƒƒãƒå‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
                        finally:
                            st.session_state.confirm_delete_batch = False
                            st.session_state.pending_delete_batch = None
                            st.rerun()
                    
                    if st.button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«", key="cancel_delete_batch"):
                        st.session_state.confirm_delete_batch = False
                        st.session_state.pending_delete_batch = None
                        st.info("å‰Šé™¤ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            else:
                st.info("å‰Šé™¤å¯èƒ½ãªãƒãƒƒãƒãŒã‚ã‚Šã¾ã›ã‚“")

            # å…¨å±¥æ­´Excelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            jst = pytz.timezone("Asia/Tokyo")
            now_str = datetime.now(jst).strftime("%y%m%d_%H%M")
            
            # Excelç”Ÿæˆï¼ˆæ—¥æœ¬èªåˆ—åã®ã¾ã¾ä½¿ç”¨ï¼‰
            output_all = io.BytesIO()
            with pd.ExcelWriter(output_all, engine='xlsxwriter') as writer:
                workbook = writer.book
                header_format = workbook.add_format({'bold': False, 'border': 0})
                
                # ç½«ç·šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆè–„ã„é»’ RGB:50,50,50ï¼‰
                border_format = workbook.add_format({
                    'border': 1,
                    'border_color': '#323232'  # RGB(50,50,50)ã‚’16é€²æ•°ã§
                })
                
                # æ³¨æ–‡ä¸€è¦§ã‚·ãƒ¼ãƒˆ
                df_all.to_excel(writer, index=False, sheet_name="å…¨æ³¨æ–‡å±¥æ­´", startrow=1, header=False)
                worksheet = writer.sheets["å…¨æ³¨æ–‡å±¥æ­´"]
                for col_num, value in enumerate(df_all.columns.values):
                    worksheet.write(0, col_num, value, header_format)

                # ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼šåˆ—åã‹ã‚‰ãƒ”ã‚¯ã‚»ãƒ«ã§å¹…ã‚’è¨­å®šï¼ˆå¤ã„XlsxWriterãªã‚‰æ–‡å­—å¹…æ›ç®—ï¼‰
                def _set_px(ws, name_to_idx: dict, col_label: str, px: int):
                    try:
                        c = name_to_idx[col_label]
                        try:
                            ws.set_column_pixels(c, c, px)
                        except AttributeError:
                            ws.set_column(c, c, round((px - 5) / 7, 2))
                    except KeyError:
                        pass

                # ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼šè¡¨å…¨ä½“ã«ç½«ç·šã‚’é©ç”¨
                def _apply_borders(ws, df, start_row=0):
                    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç¯„å›²ã«ç½«ç·šã‚’é©ç”¨"""
                    if df.empty:
                        return
                    # ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²ã‚’å–å¾—ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ + ãƒ‡ãƒ¼ã‚¿è¡Œï¼‰
                    end_row = start_row + len(df)
                    end_col = len(df.columns) - 1
                    # ç½«ç·šã‚’é©ç”¨
                    ws.conditional_format(start_row, 0, end_row, end_col, {
                        'type': 'cell',
                        'criteria': '>=',
                        'value': 0,
                        'format': border_format
                    })

                colsH = list(df_all.columns)
                idxH  = {v: i for i, v in enumerate(colsH)}
                wsH   = worksheet  # æ—¢å­˜ã® "å…¨æ³¨æ–‡å±¥æ­´" ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆ

                _set_px(wsH, idxH, "ç™ºæ³¨æ—¥", 105)
                _set_px(wsH, idxH, "ç´å“æ—¥", 105)
                _set_px(wsH, idxH, "å•†å“å", 244)
                _set_px(wsH, idxH, "å‚™è€ƒ",   244)

                # === ç½«ç·šé©ç”¨ ===
                _apply_borders(wsH, df_all, 0)  # å…¨æ³¨æ–‡å±¥æ­´

                wsH.set_landscape()
                wsH.set_paper(9)
                wsH.fit_to_pages(1, 0)
                wsH.set_margins(left=0.3, right=0.3, top=0.5, bottom=0.5)
                wsH.repeat_rows(0, 0)
            
            output_all.seek(0)
            
            st.download_button(
                label="å…¨å±¥æ­´Excelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=output_all,
                file_name=f"å…¨æ³¨æ–‡å±¥æ­´_{now_str}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="download_all_history"
            )
            
            # å…¨ãƒ‡ãƒ¼ã‚¿å‰Šé™¤æ©Ÿèƒ½
            st.markdown("---")
            
            # å…¨å‰Šé™¤ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
            if "confirm_delete_all" not in st.session_state:
                st.session_state.confirm_delete_all = False
            
            if not st.session_state.confirm_delete_all:
                col1, col2 = st.columns([1, 3])
                with col1:
                    if st.button("ğŸ—‘ï¸ å…¨ãƒ‡ãƒ¼ã‚¿å‰Šé™¤", type="secondary", key="delete_all_btn"):
                        st.session_state.confirm_delete_all = True
                        st.rerun()
                with col2:
                    st.info("å…¨æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã¨å…¨ãƒãƒƒãƒæƒ…å ±ã‚’å‰Šé™¤ã—ã¾ã™")
            else:
                st.error("âš ï¸ **æœ€çµ‚ç¢ºèª**: æœ¬å½“ã«å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ")
                st.warning(f"å‰Šé™¤å¯¾è±¡: {len(df_all)}è¡Œã®æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ + {unique_batches}å€‹ã®ãƒãƒƒãƒ")
                
                col1, col2, col3 = st.columns([1, 1, 2])
                with col1:
                    if st.button("âœ… å‰Šé™¤å®Ÿè¡Œ", type="primary", key="confirm_delete_all_btn"):
                        try:
                            with _conn() as c:
                                # ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã§å®‰å…¨ã«å‰Šé™¤
                                c.execute("BEGIN TRANSACTION")
                                try:
                                    # å…¨æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
                                    c.execute("DELETE FROM order_lines")
                                    deleted_rows = c.rowcount
                                    
                                    # å…¨ãƒãƒƒãƒæƒ…å ±ã‚’å‰Šé™¤
                                    c.execute("DELETE FROM batches")
                                    deleted_batches = c.rowcount
                                    
                                    # ã‚³ãƒŸãƒƒãƒˆ
                                    c.execute("COMMIT")
                                    
                                    st.success(f"âœ… å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸï¼ˆ{deleted_rows}è¡Œã®æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ + {deleted_batches}å€‹ã®ãƒãƒƒãƒï¼‰")
                                    st.info("ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦æœ€æ–°çŠ¶æ…‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                                    
                                except Exception as e:
                                    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
                                    c.execute("ROLLBACK")
                                    raise e
                                    
                        except Exception as e:
                            st.error(f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
                        finally:
                            st.session_state.confirm_delete_all = False
                            st.rerun()
                
                with col2:
                    if st.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", key="cancel_delete_all_btn"):
                        st.session_state.confirm_delete_all = False
                        st.info("å‰Šé™¤ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
                        st.rerun()
                
                with col3:
                    st.info("ã“ã®æ“ä½œã¯å–ã‚Šæ¶ˆã›ã¾ã›ã‚“")

elif st.session_state.get("authentication_status") is False:
    st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
elif st.session_state.get("authentication_status") is None:
    st.warning("ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")







# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆé–¢æ•°å®šç¾©å¾Œã«é…ç½®ï¼‰ ---
if not st.session_state.get("authentication_status"):
    st.sidebar.markdown("---")
    st.sidebar.subheader("æ–°è¦ã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¿½åŠ ")
    new_email = st.sidebar.text_input("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", key="new_email")
    new_name = st.sidebar.text_input("ãŠåå‰", key="new_name")
    new_company = st.sidebar.text_input("ä¼šç¤¾å", key="new_company")
    new_password = st.sidebar.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", key="new_pw")
    view_select = st.sidebar.radio(
        "ã”ç¢ºèªãã ã•ã„",
        ("è¡¨ç¤ºã—ãªã„", "åˆ©ç”¨è¦ç´„", "ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼"),
        index=0
    )
    agree_terms = st.sidebar.checkbox("åˆ©ç”¨è¦ç´„ãƒ»ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã«åŒæ„ã—ã¾ã™", key="agree_terms")

    if st.sidebar.button("è¿½åŠ "):
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        debug_info = {
            "timestamp": datetime.now().strftime("%H:%M:%S"),
            "email": new_email,
            "name": new_name,
            "company": new_company,
            "password_length": len(new_password) if new_password else 0,
            "agree_terms": agree_terms,
            "all_fields_filled": bool(new_email and new_name and new_company and new_password)
        }
        st.session_state.debug_info = debug_info
        
        if not agree_terms:
            st.sidebar.warning("åˆ©ç”¨è¦ç´„ãƒ»ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã«åŒæ„ãŒå¿…è¦ã§ã™ã€‚")
        elif new_email and new_name and new_company and new_password:
            st.sidebar.info("ãƒ‡ãƒãƒƒã‚°: ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ å‡¦ç†ã‚’é–‹å§‹")
            ok, msg = add_user(new_email, new_name, new_company, new_password)
            
            # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state.registration_result = {
                "success": ok,
                "message": msg,
                "timestamp": datetime.now().strftime("%H:%M:%S")
            }
            
            if ok:
                st.sidebar.success(msg)
                st.sidebar.info("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
                # ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿
                st.rerun()
            else:
                st.sidebar.error(msg)
        else:
            st.sidebar.warning("ã™ã¹ã¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            st.session_state.registration_result = {
                "success": False,
                "message": "å…¥åŠ›é …ç›®ãŒä¸è¶³ã—ã¦ã„ã¾ã™",
                "timestamp": datetime.now().strftime("%H:%M:%S")
            }

    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤ºã‚¨ãƒªã‚¢
    if hasattr(st.session_state, 'debug_info') and st.session_state.debug_info:
        st.sidebar.markdown("---")
        st.sidebar.subheader("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
        debug = st.session_state.debug_info
        st.sidebar.info(f"**æ™‚åˆ»**: {debug['timestamp']}")
        st.sidebar.info(f"**ãƒ¡ãƒ¼ãƒ«**: {debug['email']}")
        st.sidebar.info(f"**åå‰**: {debug['name']}")
        st.sidebar.info(f"**ä¼šç¤¾**: {debug['company']}")
        st.sidebar.info(f"**ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰é•·**: {debug['password_length']}")
        st.sidebar.info(f"**åˆ©ç”¨è¦ç´„åŒæ„**: {debug['agree_terms']}")
        st.sidebar.info(f"**å…¨é …ç›®å…¥åŠ›**: {debug['all_fields_filled']}")
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
        if st.sidebar.button("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚¯ãƒªã‚¢", key="clear_debug"):
            st.session_state.debug_info = None
            st.session_state.registration_result = None
            st.rerun()

    # èªè¨¼æƒ…å ±ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ” èªè¨¼æƒ…å ±ãƒ‡ãƒãƒƒã‚°")
    
    # YAMLãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
    st.sidebar.info(f"**YAMLãƒ‘ã‚¹**: {CRED_PATH}")
    st.sidebar.info(f"**çµ¶å¯¾ãƒ‘ã‚¹**: {CRED_PATH.resolve()}")
    if CRED_PATH.exists():
        import time
        st.sidebar.info(f"**æœ€çµ‚æ›´æ–°**: {time.ctime(CRED_PATH.stat().st_mtime)}")
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€è¦§ï¼ˆæ··ç·šç™ºè¦‹ç”¨ï¼‰
    try:
        st.sidebar.info(f"**ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹**: {[p.name for p in CRED_PATH.parent.iterdir()]}")
    except Exception as _:
        pass
    
    # YAMLèªè¨¼æƒ…å ±ï¼ˆã‚½ãƒ¼ã‚¹ãƒ»ã‚ªãƒ–ãƒ»ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ï¼‰
    try:
        yaml_config = load_credentials_from_yaml()
        st.sidebar.info(f"**YAMLãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°**: {len(yaml_config['credentials']['usernames'])}")
        st.sidebar.info(f"**YAMLãƒ¦ãƒ¼ã‚¶ãƒ¼**: {list(yaml_config['credentials']['usernames'].keys())}")
        
        # ç¾åœ¨ã®èªè¨¼æƒ…å ±
        st.sidebar.info(f"**ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°**: {len(credentials_config['credentials']['usernames'])}")
        st.sidebar.info(f"**ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼**: {list(credentials_config['credentials']['usernames'].keys())}")
        
        # YAMLãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹è¡¨ç¤ºãƒœã‚¿ãƒ³
        if st.sidebar.button("YAMLãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’è¡¨ç¤º", key="show_yaml"):
            show_yaml_contents()
            st.rerun()
            
    except Exception as e:
        st.sidebar.error(f"**YAMLèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼**: {str(e)}")

    # ç™»éŒ²çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
    if hasattr(st.session_state, 'registration_result') and st.session_state.registration_result:
        st.sidebar.markdown("---")
        st.sidebar.subheader("ğŸ“‹ ç™»éŒ²çµæœ")
        result = st.session_state.registration_result
        if result['success']:
            st.sidebar.success(f"âœ… {result['message']}")
            st.sidebar.info(f"æ™‚åˆ»: {result['timestamp']}")
        else:
            st.sidebar.error(f"âŒ {result['message']}")
            st.sidebar.info(f"æ™‚åˆ»: {result['timestamp']}")

# --- ãƒ­ã‚°ã‚¤ãƒ³ç”»é¢ã®ä¸‹ã«è¦ç´„ã‚’è¡¨ç¤ºï¼ˆã“ã“ã§é †åºèª¿æ•´ï¼‰ ---
if not st.session_state.get("authentication_status"):
    st.markdown("---")
    if 'view_select' not in locals():
        view_select = "è¡¨ç¤ºã—ãªã„"  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç›´å¾Œã®å†å®Ÿè¡Œå¯¾ç­–
    if view_select == "åˆ©ç”¨è¦ç´„":
        html = load_docx_html("åˆ©ç”¨è¦ç´„.docx")
        st.markdown("### åˆ©ç”¨è¦ç´„")
        st.markdown(html, unsafe_allow_html=True)
    elif view_select == "ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼":
        html = load_docx_html("ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼.docx")
        st.markdown("### ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼")
        st.markdown(html, unsafe_allow_html=True)
    # ä½•ã‚‚é¸æŠã—ãªã‘ã‚Œã°ä½•ã‚‚å‡ºã•ãªã„