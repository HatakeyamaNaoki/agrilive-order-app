import streamlit as st
import streamlit_authenticator as stauth
import json
import pandas as pd
import io
import pytz
from config import get_openai_api_key, is_production, load_config, get_line_channel_access_token
from parser_infomart import parse_infomart
from parser_iporter import parse_iporter
from parser_mitsubishi import parse_mitsubishi
from parser_pdf import parse_pdf_handwritten
from prompt_line import get_line_order_prompt
from docx import Document
import pdfplumber
from PIL import Image
import base64
import os
from datetime import datetime, timezone, timedelta
import requests
import sqlite3

# LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ç®¡ç†ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
LINE_ORDERS_DIR = "line_orders"
if not os.path.exists(LINE_ORDERS_DIR):
    os.makedirs(LINE_ORDERS_DIR, exist_ok=True)

def get_file_lock(file_path, timeout=10):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ã‚’å–å¾—ã™ã‚‹ï¼ˆRenderç’°å¢ƒã§ã¯ç„¡åŠ¹åŒ–ï¼‰
    """
    import os
    
    # Renderç’°å¢ƒã§ã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ã‚’ç„¡åŠ¹åŒ–ï¼ˆRead-only file systemå¯¾ç­–ï¼‰
    if os.getenv('RENDER'):
        class DummyLock:
            def __enter__(self): return self
            def __exit__(self, *args): pass
        return DummyLock()
    
    try:
        import filelock
        lock_file = f"{file_path}.lock"
        return filelock.FileLock(lock_file, timeout=timeout)
    except ImportError:
        # filelockãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼ãƒ­ãƒƒã‚¯
        class DummyLock:
            def __enter__(self): return self
            def __exit__(self, *args): pass
        return DummyLock()

def save_line_order_data(line_account, sender_name, image_data, message_text=""):
    """
    LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    """
    try:
        # ç¾åœ¨ã®æ—¥æ™‚ã‚’å–å¾—
        jst = timezone(timedelta(hours=9))
        current_time = datetime.now(jst)
        order_date = current_time.strftime("%Y/%m/%d")
        timestamp = current_time.strftime("%Y%m%d_%H%M%S")
        
        # æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        order_data = {
            "line_account": line_account,
            "sender_name": sender_name,
            "order_date": order_date,
            "timestamp": timestamp,
            "message_text": message_text,
            "image_filename": f"line_order_{timestamp}.png",
            "processed": False,
            "parsed_data": None  # è§£æçµæœã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ 
        }
        
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        image_path = os.path.join(LINE_ORDERS_DIR, order_data["image_filename"])
        with open(image_path, "wb") as f:
            f.write(image_data)
        
        # æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ä»˜ãï¼‰
        orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
        with get_file_lock(orders_file):
            orders = []
            if os.path.exists(orders_file):
                with open(orders_file, "r", encoding="utf-8") as f:
                    orders = json.load(f)
            
            orders.append(order_data)
            
            with open(orders_file, "w", encoding="utf-8") as f:
                json.dump(orders, f, ensure_ascii=False, indent=4)
        
        return True, "LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚"
    except Exception as e:
        return False, f"LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"

def save_parsed_line_order_data(timestamp, parsed_data):
    """
    LINEæ³¨æ–‡ã®è§£æçµæœã‚’ä¿å­˜
    """
    try:
        orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
        if not os.path.exists(orders_file):
            return False, "æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        
        with get_file_lock(orders_file):
            with open(orders_file, "r", encoding="utf-8") as f:
                orders = json.load(f)
            
            # æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®æ³¨æ–‡ã‚’æ›´æ–°
            for order in orders:
                if order['timestamp'] == timestamp:
                    order['parsed_data'] = parsed_data
                    order['processed'] = True
                    break
            
            with open(orders_file, "w", encoding="utf-8") as f:
                json.dump(orders, f, ensure_ascii=False, indent=4)
        
        return True, "è§£æçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ"
    except Exception as e:
        return False, f"è§£æçµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"

def get_line_orders_for_user(email):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é–¢é€£ã™ã‚‹LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    """
    try:
        orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
        if not os.path.exists(orders_file):
            print(f"âŒ orders.jsonãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {orders_file}")
            return []
        
        with open(orders_file, "r", encoding="utf-8") as f:
            all_orders = json.load(f)
        
        print(f"ğŸ“Š å…¨æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿æ•°: {len(all_orders)}")
        print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {email}")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã§ç›´æ¥ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆæ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰
        user_orders = [order for order in all_orders if order.get("line_account") == email]
        print(f"ğŸ” ãƒ¦ãƒ¼ã‚¶ãƒ¼åã§ãƒ•ã‚£ãƒ«ã‚¿: {len(user_orders)}ä»¶")
        
        # ãƒ‡ãƒãƒƒã‚°: å…¨æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¡¨ç¤º
        for i, order in enumerate(all_orders):
            print(f"ğŸ“‹ æ³¨æ–‡{i+1}: line_account={order.get('line_account')}, sender_name={order.get('sender_name')}")
        
        return user_orders
    except Exception as e:
        print(f"LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def get_all_line_orders():
    """
    ã™ã¹ã¦ã®LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆç®¡ç†è€…ç”¨ï¼‰
    """
    try:
        orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
        if not os.path.exists(orders_file):
            return []
        
        with open(orders_file, "r", encoding="utf-8") as f:
            all_orders = json.load(f)
        
        return all_orders
    except Exception as e:
        print(f"å…¨LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []



def delete_processed_line_orders():
    """
    å‡¦ç†æ¸ˆã¿ã®LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    """
    try:
        orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
        if not os.path.exists(orders_file):
            return True, "å‰Šé™¤å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"
        
        with get_file_lock(orders_file):
            with open(orders_file, "r", encoding="utf-8") as f:
                all_orders = json.load(f)
            
            # å‡¦ç†æ¸ˆã¿ã®æ³¨æ–‡ã‚’å‰Šé™¤
            original_count = len(all_orders)
            remaining_orders = [order for order in all_orders if not order.get("processed", False)]
            deleted_count = original_count - len(remaining_orders)
            
            # å‰Šé™¤ã•ã‚ŒãŸæ³¨æ–‡ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤
            deleted_orders = [order for order in all_orders if order.get("processed", False)]
            for order in deleted_orders:
                image_path = os.path.join(LINE_ORDERS_DIR, order['image_filename'])
                if os.path.exists(image_path):
                    os.remove(image_path)
            
            # æ®‹ã‚Šã®æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            with open(orders_file, "w", encoding="utf-8") as f:
                json.dump(remaining_orders, f, ensure_ascii=False, indent=4)
        
        return True, f"{deleted_count}ä»¶ã®å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
    except Exception as e:
        return False, f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}"

def delete_line_order_by_timestamp(timestamp):
    """
    æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    """
    try:
        orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
        if not os.path.exists(orders_file):
            return False, "ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        
        with get_file_lock(orders_file):
            with open(orders_file, "r", encoding="utf-8") as f:
                all_orders = json.load(f)
            
            # æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®æ³¨æ–‡ã‚’å‰Šé™¤
            original_count = len(all_orders)
            remaining_orders = [order for order in all_orders if order['timestamp'] != timestamp]
            deleted_count = original_count - len(remaining_orders)
            
            if deleted_count == 0:
                return False, "æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            
            # å‰Šé™¤ã•ã‚ŒãŸæ³¨æ–‡ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤
            deleted_orders = [order for order in all_orders if order['timestamp'] == timestamp]
            for order in deleted_orders:
                image_path = os.path.join(LINE_ORDERS_DIR, order['image_filename'])
                if os.path.exists(image_path):
                    os.remove(image_path)
            
            # æ®‹ã‚Šã®æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            with open(orders_file, "w", encoding="utf-8") as f:
                json.dump(remaining_orders, f, ensure_ascii=False, indent=4)
        
        return True, f"ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
    except Exception as e:
        return False, f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}"

def parse_line_order_with_openai(image_path, sender_name, message_text="", order_date=""):
    """
    OpenAI APIã‚’ä½¿ç”¨ã—ã¦LINEæ³¨æ–‡ç”»åƒã‚’è§£æ
    """
    try:
        api_key = get_openai_api_key()
        if not api_key:
            raise Exception("OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        import openai
        client = openai.OpenAI(api_key=api_key)
        
        # ç”»åƒã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        system_prompt = get_line_order_prompt()
        
        # å—ä¿¡æ—¥æ™‚ã‚’å«ã‚€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        user_message = f"é€ä¿¡è€…: {sender_name}\nå—ä¿¡æ—¥: {order_date}\nãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {message_text}\n\nã“ã®LINEæ³¨æ–‡ã‚’è§£æã—ã¦ãã ã•ã„ã€‚å—ä¿¡æ—¥ã‚’åŸºæº–ã«ç´å“æ—¥ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚"
        
        # OpenAI APIã‚’å‘¼ã³å‡ºã—
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_message},
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_data}"}}
                    ]
                }
            ],
            max_tokens=2000,
            temperature=0.1
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
        content = response.choices[0].message.content
        
        # JSONã¨ã—ã¦è§£æ
        try:
            cleaned_content = content.strip()
            if cleaned_content.startswith('```json'):
                cleaned_content = cleaned_content[7:]
            if cleaned_content.endswith('```'):
                cleaned_content = cleaned_content[:-3]
            cleaned_content = cleaned_content.strip()
            
            parsed_data = json.loads(cleaned_content)
            
            # ç™ºæ³¨æ—¥ãŒç©ºã®å ´åˆã¯å—ä¿¡æ—¥ã‚’è¨­å®š
            if not parsed_data.get("order_date"):
                parsed_data["order_date"] = order_date
            
            return parsed_data
        except json.JSONDecodeError as e:
            raise Exception(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
            
    except Exception as e:
        raise Exception(f"LINEæ³¨æ–‡è§£æã‚¨ãƒ©ãƒ¼: {e}")

def extract_pdf_images(pdf_bytes):
    """
    PDFã‹ã‚‰ãƒšãƒ¼ã‚¸å…¨ä½“ã‚’ç”»åƒã¨ã—ã¦æŠ½å‡ºã—ã¦PIL Imageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
    """
    try:
        with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
            page_images = []
            for page_num, page in enumerate(pdf.pages):
                try:
                    # ãƒšãƒ¼ã‚¸ã‚’ç”»åƒã¨ã—ã¦ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
                    page_image = page.to_image()
                    if page_image:
                        pil_image = page_image.original
                        page_images.append({
                            'page': page_num + 1,
                            'image': pil_image
                        })
                except Exception as e:
                    st.warning(f"ãƒšãƒ¼ã‚¸ {page_num + 1} ã®ç”»åƒåŒ–ã«å¤±æ•—: {e}")
            
            return page_images
    except Exception as e:
        st.error(f"PDFç”»åƒæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return []

def display_pdf_images(images, filename):
    """
    PDFã‹ã‚‰æŠ½å‡ºã—ãŸãƒšãƒ¼ã‚¸ç”»åƒã‚’Webä¸Šã«è¡¨ç¤º
    """
    if not images:
        st.info(f"{filename} ã‹ã‚‰ç”»åƒã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    st.subheader(f"ğŸ“„ {filename} ã®ç”»åƒè¡¨ç¤º")
    
    # ãƒšãƒ¼ã‚¸ç”»åƒã‚’è¡¨ç¤º
    if len(images) == 1:
        img_data = images[0]
        st.write(f"**ãƒšãƒ¼ã‚¸ {img_data['page']}**")
        st.image(img_data['image'], caption=f"ãƒšãƒ¼ã‚¸ {img_data['page']}", width=400)
    else:
        # è¤‡æ•°ãƒšãƒ¼ã‚¸ã®å ´åˆã¯2ãƒšãƒ¼ã‚¸ãšã¤1è¡Œã§è¡¨ç¤º
        for i in range(0, len(images), 2):
            cols = st.columns(2)
            for j in range(2):
                if i + j < len(images):
                    img_data = images[i + j]
                    with cols[j]:
                        st.write(f"**ãƒšãƒ¼ã‚¸ {img_data['page']}**")
                        st.image(img_data['image'], caption=f"ãƒšãƒ¼ã‚¸ {img_data['page']}", width=400)

def is_admin(username):
    """
    ç®¡ç†è€…ã‹ã©ã†ã‹ã‚’åˆ¤å®š
    """
    # ç®¡ç†è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®ãƒªã‚¹ãƒˆ
    admin_emails = [
        "n.hatakeyama@agrilive.co.jp"  # å®Ÿéš›ã®ç®¡ç†è€…ãƒ¡ãƒ¼ãƒ«
    ]
    return username in admin_emails

def get_all_users():
    """
    ã™ã¹ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—ï¼ˆåŸºæœ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ + å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰
    """
    try:
        base_credentials = load_credentials()
        dynamic_users = load_dynamic_users()
        
        all_users = []
        
        # åŸºæœ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆSecret Filesï¼‰
        for email, user_info in base_credentials['credentials']['usernames'].items():
            all_users.append({
                "email": email,
                "name": user_info.get("name", ""),
                "company": user_info.get("company", ""),
                "type": "åŸºæœ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆSecret Filesï¼‰",
                "created_date": "ç®¡ç†è€…è¨­å®š"
            })
        
        # å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼
        for email, user_info in dynamic_users.get("users", {}).items():
            all_users.append({
                "email": email,
                "name": user_info.get("name", ""),
                "company": user_info.get("company", ""),
                "type": "å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼",
                "created_date": "æ–°è¦ç™»éŒ²"
            })
        
        return all_users
    except Exception as e:
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def load_docx_html(filepath):
    doc = Document(filepath)
    html = ""
    for para in doc.paragraphs:
        # ç©ºè¡Œã‚‚æ”¹è¡Œã¨ã—ã¦åæ˜ 
        html += f"{para.text}<br>"
    return html

def detect_csv_type(content_bytes):
    ENCODINGS = ["utf-8-sig", "utf-8", "cp932", "shift_jis"]
    debug_log = []
    for enc in ENCODINGS:
        try:
            file_str = content_bytes.decode(enc)
            sio = io.StringIO(file_str)
            first_line = sio.readline().strip().split(",")
            debug_log.append(f"[{enc}] first_line={first_line}")
            cell0 = first_line[0].replace('"', '').replace("'", '').strip() if first_line else ""
            if cell0 == "H":
                debug_log.append(f"åˆ¤å®š: infomart ({enc})")
                return 'infomart', enc, debug_log
            elif cell0 == "ä¼ç¥¨ç•ªå·":
                debug_log.append(f"åˆ¤å®š: iporter ({enc})")
                return 'iporter', enc, debug_log
        except Exception as e:
            debug_log.append(f"[{enc}] error: {e}")
    debug_log.append("åˆ¤å®š: unknown")
    return 'unknown', None, debug_log

def validate_email(email):
    """
    ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®å½¢å¼ã‚’æ¤œè¨¼ã™ã‚‹
    """
    import re
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    if not re.match(pattern, email):
        return False, "æœ‰åŠ¹ãªãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    return True, "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¯æœ‰åŠ¹ã§ã™"

def validate_password(password):
    """
    ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®å¼·åº¦ã‚’æ¤œè¨¼ã™ã‚‹
    """
    if len(password) < 8:
        return False, "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯8æ–‡å­—ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
    
    if not any(c.isupper() for c in password):
        return False, "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã«ã¯å¤§æ–‡å­—ãŒå«ã¾ã‚Œã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
    
    if not any(c.islower() for c in password):
        return False, "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã«ã¯å°æ–‡å­—ãŒå«ã¾ã‚Œã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
    
    if not any(c.isdigit() for c in password):
        return False, "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã«ã¯æ•°å­—ãŒå«ã¾ã‚Œã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
    
    return True, "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯æœ‰åŠ¹ã§ã™"

def add_user(email, name, company, password):
    """
    å‹•çš„ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¿½åŠ ã™ã‚‹ï¼ˆSQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½¿ç”¨ï¼‰
    """
    import os
    
    print(f"add_useré–‹å§‹: email={email}, name={name}, company={company}")
    
    # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹å½¢å¼ãƒã‚§ãƒƒã‚¯
    is_valid_email, email_message = validate_email(email)
    print(f"ãƒ¡ãƒ¼ãƒ«ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³: {is_valid_email}, {email_message}")
    if not is_valid_email:
        return False, email_message
    
    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å¼·åº¦ãƒã‚§ãƒƒã‚¯
    is_valid_pw, pw_message = validate_password(password)
    print(f"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³: {is_valid_pw}, {pw_message}")
    if not is_valid_pw:
        return False, pw_message
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§é‡è¤‡ãƒã‚§ãƒƒã‚¯
    if check_user_exists_in_db(email):
        print(f"é‡è¤‡ã‚¨ãƒ©ãƒ¼: {email} ã¯æ—¢ã«ç™»éŒ²æ¸ˆã¿")
        return False, "ã“ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¯æ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™ã€‚"
    
    # åŸºæœ¬èªè¨¼æƒ…å ±ã‚‚ç¢ºèªï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼‰
    base_credentials = load_credentials()
    if email in base_credentials['credentials']['usernames']:
        print(f"é‡è¤‡ã‚¨ãƒ©ãƒ¼: {email} ã¯åŸºæœ¬èªè¨¼æƒ…å ±ã«æ—¢ã«å­˜åœ¨")
        return False, "ã“ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¯æ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™ã€‚"
    
    # æ­£ã—ã„ãƒãƒƒã‚·ãƒ¥åŒ–æ–¹æ³•ï¼ˆbcryptç›´æ¥ä½¿ç”¨ï¼‰
    import bcrypt
    hashed_pw = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¿½åŠ 
    save_result = add_user_to_db(email, name, company, hashed_pw)
    print(f"ä¿å­˜çµæœ: {save_result}")
    if save_result:
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ æˆåŠŸ: {email}")
        return True, "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚"
    else:
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ å¤±æ•—: {email}")
        return False, "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"



def merge_credentials(base_credentials, dynamic_users):
    """
    åŸºæœ¬èªè¨¼æƒ…å ±ã¨å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’çµ±åˆã™ã‚‹
    """
    merged_credentials = base_credentials.copy()
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    print(f"åŸºæœ¬èªè¨¼æƒ…å ±ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(base_credentials['credentials']['usernames'])}")
    print(f"å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(dynamic_users.get('users', {}))}")
    
    # å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’åŸºæœ¬èªè¨¼æƒ…å ±ã«è¿½åŠ 
    for email, user_data in dynamic_users.get("users", {}).items():
        print(f"å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ : {email} - {user_data.get('name', 'N/A')}")
        # streamlit-authenticatorãŒæœŸå¾…ã™ã‚‹å½¢å¼ï¼ˆåŸºæœ¬èªè¨¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨åŒã˜è¾æ›¸å½¢å¼ï¼‰
        merged_credentials["credentials"]["usernames"][email] = user_data
    
    print(f"çµ±åˆå¾Œãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(merged_credentials['credentials']['usernames'])}")
    print(f"çµ±åˆå¾Œãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§: {list(merged_credentials['credentials']['usernames'].keys())}")
    
    return merged_credentials

# --- èªè¨¼ ---
def load_credentials():
    """
    èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
    æœ¬ç•ªç’°å¢ƒ: Render Secrets Filesã‹ã‚‰
    ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ: ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰
    """
    import os
    
    # æœ¬ç•ªç’°å¢ƒï¼ˆRenderï¼‰ã®å ´åˆ
    if os.getenv('RENDER'):
        try:
            # Secret Filesã‹ã‚‰èª­ã¿è¾¼ã¿ã‚’è©¦è¡Œ
            secret_paths = [
                '/etc/secrets/credentials.json',
                'credentials.json',
                './credentials.json'
            ]
            
            for path in secret_paths:
                if os.path.exists(path):
                    with open(path, "r", encoding="utf-8") as f:
                        return json.load(f)
            
            # Secret Filesã§è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€é€šå¸¸ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
            with open("credentials.json", "r", encoding="utf-8") as f:
                return json.load(f)
                
        except Exception as e:
            print(f"èªè¨¼æƒ…å ±èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é€šå¸¸ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
            with open("credentials.json", "r", encoding="utf-8") as f:
                return json.load(f)
    
    # ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒã®å ´åˆ
    with open("credentials.json", "r", encoding="utf-8") as f:
        return json.load(f)

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
init_database()

# åŸºæœ¬èªè¨¼æƒ…å ±ã¨å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’çµ±åˆ
base_credentials = load_credentials()
dynamic_users = load_users_from_db()
credentials_config = merge_credentials(base_credentials, dynamic_users)

# ãƒ‡ãƒãƒƒã‚°æƒ…å ±
total_users = len(credentials_config['credentials']['usernames'])
dynamic_count = len(dynamic_users.get('users', {}))
print(f"èªè¨¼æƒ…å ±çµ±åˆ: ç·ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°={total_users}, å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°={dynamic_count}")

# è©³ç´°ãƒ‡ãƒãƒƒã‚°æƒ…å ±
print("=== èªè¨¼æƒ…å ±è©³ç´° ===")
print(f"åŸºæœ¬èªè¨¼ãƒ¦ãƒ¼ã‚¶ãƒ¼: {list(base_credentials['credentials']['usernames'].keys())}")
print(f"å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼: {list(dynamic_users.get('users', {}).keys())}")
print(f"çµ±åˆå¾Œãƒ¦ãƒ¼ã‚¶ãƒ¼: {list(credentials_config['credentials']['usernames'].keys())}")

# åŸºæœ¬èªè¨¼æƒ…å ±ã®å½¢å¼ã‚’ç¢ºèª
print("=== åŸºæœ¬èªè¨¼æƒ…å ±ã®å½¢å¼ç¢ºèª ===")
for email, user_data in base_credentials['credentials']['usernames'].items():
    print(f"åŸºæœ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ - {email}:")
    print(f"  ãƒ‡ãƒ¼ã‚¿å‹: {type(user_data)}")
    print(f"  ãƒ‡ãƒ¼ã‚¿å†…å®¹: {user_data}")

# å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è©³ç´°æƒ…å ±
for email, password in dynamic_users.get('users', {}).items():
    print(f"å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼è©³ç´° - {email}:")
    user_info = dynamic_users.get('user_info', {}).get(email, {})
    print(f"  åå‰: {user_info.get('name', 'N/A')}")
    print(f"  ä¼šç¤¾: {user_info.get('company', 'N/A')}")
    print(f"  ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰é•·: {len(password)}")
    print(f"  ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å…ˆé ­: {password[:20]}...")



authenticator = stauth.Authenticate(
    credentials=credentials_config['credentials'],
    cookie_name=credentials_config['cookie']['name'],
    key=credentials_config['cookie']['key'],
    expiry_days=credentials_config['cookie']['expiry_days'],
    preauthorized=credentials_config['preauthorized']
)
st.set_page_config(page_title="å—æ³¨é›†è¨ˆã‚¢ãƒ—ãƒªï¼ˆã‚¢ã‚°ãƒªãƒ©ã‚¤ãƒ–ï¼‰", layout="wide")

# è‡ªå‹•æ›´æ–°æ©Ÿèƒ½
if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°", key="refresh_data"):
    st.rerun()

st.image("ä¼šç¤¾ãƒ­ã‚´.png", width=220)
st.title("å—æ³¨é›†è¨ˆã‚¢ãƒ—ãƒªï¼ˆã‚¢ã‚°ãƒªãƒ©ã‚¤ãƒ–ï¼‰")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
if not st.session_state.get("authentication_status"):
    st.sidebar.markdown("---")
    st.sidebar.subheader("æ–°è¦ã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¿½åŠ ")
    new_email = st.sidebar.text_input("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", key="new_email")
    new_name = st.sidebar.text_input("ãŠåå‰", key="new_name")
    new_company = st.sidebar.text_input("ä¼šç¤¾å", key="new_company")
    new_password = st.sidebar.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", key="new_pw")
    view_select = st.sidebar.radio(
        "ã”ç¢ºèªãã ã•ã„",
        ("è¡¨ç¤ºã—ãªã„", "åˆ©ç”¨è¦ç´„", "ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼"),
        index=0
    )
    agree_terms = st.sidebar.checkbox("åˆ©ç”¨è¦ç´„ãƒ»ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã«åŒæ„ã—ã¾ã™", key="agree_terms")

    if st.sidebar.button("è¿½åŠ "):
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        debug_info = {
            "timestamp": datetime.now().strftime("%H:%M:%S"),
            "email": new_email,
            "name": new_name,
            "company": new_company,
            "password_length": len(new_password) if new_password else 0,
            "agree_terms": agree_terms,
            "all_fields_filled": bool(new_email and new_name and new_company and new_password)
        }
        st.session_state.debug_info = debug_info
        
        if not agree_terms:
            st.sidebar.warning("åˆ©ç”¨è¦ç´„ãƒ»ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã«åŒæ„ãŒå¿…è¦ã§ã™ã€‚")
        elif new_email and new_name and new_company and new_password:
            st.sidebar.info("ãƒ‡ãƒãƒƒã‚°: ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ å‡¦ç†ã‚’é–‹å§‹")
            ok, msg = add_user(new_email, new_name, new_company, new_password)
            
            # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state.registration_result = {
                "success": ok,
                "message": msg,
                "timestamp": datetime.now().strftime("%H:%M:%S")
            }
            
            if ok:
                st.sidebar.success(msg)
                st.sidebar.info("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
                # ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿
                st.rerun()
            else:
                st.sidebar.error(msg)
        else:
            st.sidebar.warning("ã™ã¹ã¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            st.session_state.registration_result = {
                "success": False,
                "message": "å…¥åŠ›é …ç›®ãŒä¸è¶³ã—ã¦ã„ã¾ã™",
                "timestamp": datetime.now().strftime("%H:%M:%S")
            }

    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤ºã‚¨ãƒªã‚¢
    if hasattr(st.session_state, 'debug_info') and st.session_state.debug_info:
        st.sidebar.markdown("---")
        st.sidebar.subheader("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
        debug = st.session_state.debug_info
        st.sidebar.info(f"**æ™‚åˆ»**: {debug['timestamp']}")
        st.sidebar.info(f"**ãƒ¡ãƒ¼ãƒ«**: {debug['email']}")
        st.sidebar.info(f"**åå‰**: {debug['name']}")
        st.sidebar.info(f"**ä¼šç¤¾**: {debug['company']}")
        st.sidebar.info(f"**ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰é•·**: {debug['password_length']}")
        st.sidebar.info(f"**åˆ©ç”¨è¦ç´„åŒæ„**: {debug['agree_terms']}")
        st.sidebar.info(f"**å…¨é …ç›®å…¥åŠ›**: {debug['all_fields_filled']}")
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
        if st.sidebar.button("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚¯ãƒªã‚¢", key="clear_debug"):
            st.session_state.debug_info = None
            st.session_state.registration_result = None
            st.rerun()

    # ç™»éŒ²çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
    if hasattr(st.session_state, 'registration_result') and st.session_state.registration_result:
        st.sidebar.markdown("---")
        st.sidebar.subheader("ğŸ“‹ ç™»éŒ²çµæœ")
        result = st.session_state.registration_result
        if result['success']:
            st.sidebar.success(f"âœ… {result['message']}")
            st.sidebar.info(f"æ™‚åˆ»: {result['timestamp']}")
        else:
            st.sidebar.error(f"âŒ {result['message']}")
            st.sidebar.info(f"æ™‚åˆ»: {result['timestamp']}")

# --- ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã‚’æç”»ï¼ˆå¿…ãšã“ã“ã§è¡¨ç¤ºï¼ï¼‰ ---
# ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
if st.session_state.get('debug_info'):
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ” èªè¨¼ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
    st.sidebar.info(f"**èªè¨¼çŠ¶æ…‹**: {st.session_state.get('authentication_status')}")
    st.sidebar.info(f"**ãƒ¦ãƒ¼ã‚¶ãƒ¼å**: {st.session_state.get('username')}")
    st.sidebar.info(f"**åå‰**: {st.session_state.get('name')}")

authenticator.login(
    location='main',
    fields={
        "Form name": "Login",
        "Username": "Email",
        "Password": "Password",
        "Login": "Login"
    }
)

# --- ãƒ­ã‚°ã‚¤ãƒ³ç”»é¢ã®ä¸‹ã«è¦ç´„ã‚’è¡¨ç¤ºï¼ˆã“ã“ã§é †åºèª¿æ•´ï¼‰ ---
if not st.session_state.get("authentication_status"):
    st.markdown("---")
    if 'view_select' not in locals():
        view_select = "è¡¨ç¤ºã—ãªã„"  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç›´å¾Œã®å†å®Ÿè¡Œå¯¾ç­–
    if view_select == "åˆ©ç”¨è¦ç´„":
        html = load_docx_html("åˆ©ç”¨è¦ç´„.docx")
        st.markdown("### åˆ©ç”¨è¦ç´„")
        st.markdown(html, unsafe_allow_html=True)
    elif view_select == "ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼":
        html = load_docx_html("ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼.docx")
        st.markdown("### ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼")
        st.markdown(html, unsafe_allow_html=True)
    # ä½•ã‚‚é¸æŠã—ãªã‘ã‚Œã°ä½•ã‚‚å‡ºã•ãªã„

# --- ãƒ­ã‚°ã‚¤ãƒ³å¾Œã®ç”»é¢ ---
if st.session_state.get("authentication_status"):
    username = st.session_state.get("username", "")
    name = st.session_state.get("name", "")
    config = load_config(user_id=username)
    
    # ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³ã‚’ä¸€ç•ªä¸Šã«é…ç½®
    authenticator.logout('ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ', 'sidebar')
    st.success(f"{name} ã•ã‚“ã€ã‚ˆã†ã“ãï¼")
    
    # LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“± LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿")
    
    # æœ€æ–°ã®LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
    line_orders = get_line_orders_for_user(username)
    if line_orders:
        st.sidebar.success(f"ğŸ“± LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿: {len(line_orders)}ä»¶")
        latest_orders = sorted(line_orders, key=lambda x: x['timestamp'], reverse=True)[:3]
        for order in latest_orders:
            with st.sidebar.expander(f"ğŸ“‹ {order['sender_name']} - {order['order_date']}"):
                st.write(f"**é€ä¿¡è€…**: {order['sender_name']}")
                st.write(f"**å—ä¿¡æ—¥**: {order['order_date']}")
                if order.get('processed', False):
                    st.success("âœ… å‡¦ç†æ¸ˆã¿")
                else:
                    st.warning("â³ æœªå‡¦ç†")
                
                # å‰Šé™¤ãƒœã‚¿ãƒ³
                if st.sidebar.button(f"ğŸ—‘ï¸ å‰Šé™¤", key=f"sidebar_delete_{order['timestamp']}"):
                    success, message = delete_line_order_by_timestamp(order['timestamp'])
                    if success:
                        st.sidebar.success(message)
                        st.rerun()
                    else:
                        st.sidebar.error(message)
    else:
        st.sidebar.info("LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“")
        st.sidebar.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {username}")
    
    # ç®¡ç†è€…ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
    try:
        if is_admin(username):
            st.sidebar.markdown("---")
            st.sidebar.subheader("ç®¡ç†è€…ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
            
            if st.sidebar.button("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ³ç¢ºèª"):
                st.session_state.show_admin_dashboard = True
            
            if st.sidebar.button("é€šå¸¸ç”»é¢ã«æˆ»ã‚‹"):
                st.session_state.show_admin_dashboard = False
        
        # ç®¡ç†è€…ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®è¡¨ç¤º
        if is_admin(username) and st.session_state.get("show_admin_dashboard", False):
            st.markdown("---")
            st.subheader("ğŸ“Š ç®¡ç†è€…ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
            
            # çµ±è¨ˆæƒ…å ±
            all_users = get_all_users()
            base_users = [u for u in all_users if u["type"] == "åŸºæœ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆSecret Filesï¼‰"]
            dynamic_users = [u for u in all_users if u["type"] == "å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼"]
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ç·ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°", len(all_users))
            with col2:
                st.metric("åŸºæœ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°", len(base_users))
            with col3:
                st.metric("å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°", len(dynamic_users))
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§
            st.subheader("ğŸ‘¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§")
            
            if all_users:
                # DataFrameã«å¤‰æ›
                df_users = pd.DataFrame(all_users)
                df_users = df_users[["email", "name", "company", "type", "created_date"]]
                df_users.columns = ["ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", "ãŠåå‰", "ä¼šç¤¾å", "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ã‚¤ãƒ—", "ä½œæˆæ—¥"]
                
                st.dataframe(
                    df_users,
                    use_container_width=True,
                    hide_index=True
                )
                
                # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
                csv = df_users.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv,
                    file_name=f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    mime="text/csv"
                )
            else:
                st.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            
            # LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿æƒ…å ±
            st.subheader("ğŸ“± LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿æƒ…å ±")
            
            all_line_orders = get_all_line_orders()
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ç·LINEæ³¨æ–‡æ•°", len(all_line_orders))
            with col2:
                processed_orders = [order for order in all_line_orders if order.get("processed", False)]
                st.metric("å‡¦ç†æ¸ˆã¿æ³¨æ–‡æ•°", len(processed_orders))
            
            # å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ãƒœã‚¿ãƒ³
            if processed_orders:
                if st.button("ğŸ—‘ï¸ å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å‰Šé™¤", type="secondary"):
                    success, message = delete_processed_line_orders()
                    if success:
                        st.success(message)
                        st.rerun()
                    else:
                        st.error(message)
            
            # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
            st.subheader("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
            col1, col2 = st.columns(2)
            
            with col1:
                st.info(f"**ç’°å¢ƒ**: {'æœ¬ç•ªç’°å¢ƒ' if is_production() else 'é–‹ç™ºç’°å¢ƒ'}")
                st.info(f"**ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼**: {username}")
            
            with col2:
                st.info(f"**åŸºæœ¬èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«**: credentials.json")
                st.info(f"**å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«**: dynamic_users.json")
            
            st.stop()  # ç®¡ç†è€…ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºæ™‚ã¯é€šå¸¸ã®æ©Ÿèƒ½ã‚’ã‚¹ã‚­ãƒƒãƒ—
    except Exception as e:
        st.error(f"ç®¡ç†è€…ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯é€šå¸¸ã®æ©Ÿèƒ½ã‚’ç¶šè¡Œ

    # ãƒ‡ãƒãƒƒã‚°ç”¨: å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®ç¢ºèªï¼ˆé–‹ç™ºæ™‚ã®ã¿è¡¨ç¤ºï¼‰
    if not is_production():
        st.sidebar.markdown("---")
        st.sidebar.subheader("ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
        try:
            dynamic_users = load_dynamic_users()
            st.sidebar.info(f"å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(dynamic_users.get('users', {}))}")
            if dynamic_users.get('users'):
                st.sidebar.json(dynamic_users)
        except Exception as e:
            st.sidebar.error(f"å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æƒ…å ±ã‚’è¡¨ç¤º
        st.sidebar.markdown("---")
        st.sidebar.subheader("ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æƒ…å ±")
        import os
        current_dir = os.getcwd()
        st.sidebar.info(f"ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {current_dir}")
        
        # ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        files_to_check = [
            "dynamic_users.json",
            "credentials.json", 
            "app.py"
        ]
        
        for file in files_to_check:
            file_path = os.path.join(current_dir, file)
            exists = os.path.exists(file_path)
            status = "âœ… å­˜åœ¨" if exists else "âŒ ä¸å­˜åœ¨"
            st.sidebar.info(f"{file}: {status}")
            
            if exists:
                try:
                    size = os.path.getsize(file_path)
                    st.sidebar.info(f"  - ã‚µã‚¤ã‚º: {size} bytes")
                except:
                    pass

    # OpenAI APIã‚­ãƒ¼è¨­å®šï¼ˆé–‹ç™ºç’°å¢ƒã®ã¿ï¼‰
    if not is_production():
        st.sidebar.markdown("---")
        st.sidebar.subheader("OpenAI APIè¨­å®šï¼ˆé–‹ç™ºç’°å¢ƒï¼‰")
        
        # ç¾åœ¨ã®APIã‚­ãƒ¼ã‚’å–å¾—
        try:
            current_key = get_openai_api_key()
            api_key = st.sidebar.text_input(
                "OpenAI APIã‚­ãƒ¼",
                value=current_key,
                type="password",
                help="PDFè§£æã«å¿…è¦ãªOpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
            )
            
            if api_key and api_key != current_key:
                # æ–°ã—ã„APIã‚­ãƒ¼ã‚’è¨­å®š
                os.environ['OPENAI_API_KEY'] = api_key
                st.sidebar.success("APIã‚­ãƒ¼ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸ")
            elif api_key:
                st.sidebar.success("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
            else:
                st.sidebar.warning("PDFè§£æã«ã¯APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")
        except Exception as e:
            st.sidebar.error(f"APIã‚­ãƒ¼ã®å–å¾—ã«å¤±æ•—: {e}")
            st.sidebar.info("ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºæ™‚ã¯.envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„")
    else:
        # æœ¬ç•ªç’°å¢ƒã®å ´åˆ - APIã‚­ãƒ¼æƒ…å ±ã¯è¡¨ç¤ºã—ãªã„
        pass

    # LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
    line_orders = get_line_orders_for_user(username)
    
    # LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
    st.subheader("ğŸ“± LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿")
    
    # çµ±è¨ˆæƒ…å ±
    if line_orders:
        total_orders = len(line_orders)
        unprocessed_orders = [order for order in line_orders if not order.get("processed", False)]
        processed_orders = [order for order in line_orders if order.get("processed", False)]
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç·æ³¨æ–‡æ•°", total_orders)
        with col2:
            st.metric("æœªå‡¦ç†", len(unprocessed_orders))
        with col3:
            st.metric("å‡¦ç†æ¸ˆã¿", len(processed_orders))
    
    # æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
    with st.expander("ğŸ“¤ LINEç”»åƒã‚’æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"):
        uploaded_line_image = st.file_uploader(
            "LINEã®æ³¨æ–‡ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['png', 'jpg', 'jpeg'],
            key="line_image_upload"
        )
        
        if uploaded_line_image:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.image(uploaded_line_image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸLINEç”»åƒ", width=400)
            
            with col2:
                sender_name = st.text_input("é€ä¿¡è€…å", value="", key="sender_name")
                message_text = st.text_area("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰", key="message_text")
                
                if st.button("LINEæ³¨æ–‡ã¨ã—ã¦ä¿å­˜", key="save_line_order"):
                    try:
                        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                        image_data = uploaded_line_image.read()
                        
                        success, message = save_line_order_data(
                            username,  # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’LINEã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã¨ã—ã¦ä½¿ç”¨
                            sender_name or "ä¸æ˜",
                            image_data,
                            message_text
                        )
                        
                        if success:
                            st.success("LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                            st.info(f"ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿: é€ä¿¡è€…={sender_name or 'ä¸æ˜'}, ãƒ¦ãƒ¼ã‚¶ãƒ¼={username}")
                            
                            # ä¿å­˜å¾Œã®ãƒ‡ãƒ¼ã‚¿ç¢ºèª
                            st.info("ä¿å­˜å¾Œã®ãƒ‡ãƒ¼ã‚¿ç¢ºèª:")
                            orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
                            if os.path.exists(orders_file):
                                with open(orders_file, "r", encoding="utf-8") as f:
                                    all_orders = json.load(f)
                                st.info(f"- å…¨æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿æ•°: {len(all_orders)}")
                                for i, order in enumerate(all_orders[-3:]):  # æœ€æ–°3ä»¶
                                    st.info(f"- æ³¨æ–‡{i+1}: line_account={order.get('line_account')}, sender_name={order.get('sender_name')}")
                            
                            # 3ç§’é–“å¾…æ©Ÿã—ã¦ã‹ã‚‰ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿
                            import time
                            time.sleep(3)
                            st.rerun()
                        else:
                            st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {message}")
                    except Exception as e:
                        st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                        st.error(f"è©³ç´°: {str(e)}")
    
    # æ—¢å­˜ã®LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    if line_orders:
        
        # æœªå‡¦ç†ã®æ³¨æ–‡ã®ã¿ã‚’è¡¨ç¤º
        unprocessed_orders = [order for order in line_orders if not order.get("processed", False)]
        
        if unprocessed_orders:
            st.info(f"æœªå‡¦ç†ã®LINEæ³¨æ–‡ãŒ {len(unprocessed_orders)} ä»¶ã‚ã‚Šã¾ã™ã€‚")
            
            # ä¸€æ‹¬è§£æãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("ğŸš€ ä¸€æ‹¬è§£æé–‹å§‹", type="primary", key="batch_parse"):
                    try:
                        with st.spinner(f"{len(unprocessed_orders)}ä»¶ã®LINEæ³¨æ–‡ã‚’ä¸€æ‹¬è§£æä¸­..."):
                            processed_count = 0
                            error_count = 0
                            
                            for order in unprocessed_orders:
                                try:
                                    image_path = os.path.join(LINE_ORDERS_DIR, order['image_filename'])
                                    if os.path.exists(image_path):
                                        # OpenAI APIã§è§£æ
                                        parsed_data = parse_line_order_with_openai(
                                            image_path, 
                                            order['sender_name'], 
                                            order.get('message_text', ''),
                                            order['order_date'] # å—ä¿¡æ—¥æ™‚ã‚’æ¸¡ã™
                                        )
                                        
                                        # è§£æçµæœã‚’ä¿å­˜
                                        success, message = save_parsed_line_order_data(order['timestamp'], parsed_data)
                                        if not success:
                                            st.error(f"è§£æçµæœã®ä¿å­˜ã«å¤±æ•—: {message}")
                                        
                                        processed_count += 1
                                    else:
                                        error_count += 1
                                except Exception as e:
                                    error_count += 1
                                    st.error(f"è§£æã‚¨ãƒ©ãƒ¼ ({order['sender_name']}): {e}")
                            
                            st.success(f"ä¸€æ‹¬è§£æå®Œäº†ï¼ æˆåŠŸ: {processed_count}ä»¶, ã‚¨ãƒ©ãƒ¼: {error_count}ä»¶")
                            st.rerun()
                    except Exception as e:
                        st.error(f"ä¸€æ‹¬è§£æã‚¨ãƒ©ãƒ¼: {e}")
            
            with col2:
                if st.button("ğŸ—‘ï¸ æœªå‡¦ç†ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å‰Šé™¤", type="secondary", key="batch_delete"):
                    try:
                        deleted_count = 0
                        for order in unprocessed_orders:
                            success, message = delete_line_order_by_timestamp(order['timestamp'])
                            if success:
                                deleted_count += 1
                        
                        st.success(f"æœªå‡¦ç†ãƒ‡ãƒ¼ã‚¿ã‚’ {deleted_count} ä»¶å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                        st.rerun()
                    except Exception as e:
                        st.error(f"ä¸€æ‹¬å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
            
            st.markdown("---")
            
            for i, order in enumerate(unprocessed_orders):
                with st.expander(f"ğŸ“‹ {order['sender_name']} - {order['order_date']} ({order['timestamp']})"):
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        # ç”»åƒã‚’è¡¨ç¤º
                        image_path = os.path.join(LINE_ORDERS_DIR, order['image_filename'])
                        if os.path.exists(image_path):
                            st.image(image_path, caption=f"LINEæ³¨æ–‡ç”»åƒ", width=400)
                        
                        # æ³¨æ–‡æƒ…å ±ã‚’è¡¨ç¤º
                        st.write(f"**é€ä¿¡è€…**: {order['sender_name']}")
                        st.write(f"**å—ä¿¡æ—¥**: {order['order_date']}")
                        if order.get('message_text'):
                            st.write(f"**ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**: {order['message_text']}")
                    
                    with col2:
                        # è§£æãƒœã‚¿ãƒ³
                        if st.button(f"è§£æé–‹å§‹", key=f"parse_{order['timestamp']}"):
                            try:
                                with st.spinner("LINEæ³¨æ–‡ã‚’è§£æä¸­..."):
                                    # OpenAI APIã§è§£æ
                                    parsed_data = parse_line_order_with_openai(
                                        image_path, 
                                        order['sender_name'], 
                                        order.get('message_text', ''),
                                        order['order_date'] # å—ä¿¡æ—¥æ™‚ã‚’æ¸¡ã™
                                    )
                                    
                                    # æ¨™æº–å½¢å¼ã«å¤‰æ›
                                    records = []
                                    delivery_date = parsed_data.get("delivery_date", "")
                                    items = parsed_data.get("items", [])
                                    
                                    for item in items:
                                        record = {
                                            "order_id": item.get("order_id", ""),
                                            "order_date": order['order_date'],  # Webã‚¢ãƒ—ãƒªã§ã®å—ä¿¡æ—¥ã‚’ä½¿ç”¨
                                            "delivery_date": delivery_date,
                                            "partner_name": parsed_data.get("partner_name", order['sender_name']),
                                            "product_code": item.get("product_code", ""),
                                            "product_name": item.get("product_name", ""),
                                            "quantity": item.get("quantity", ""),
                                            "unit": item.get("unit", ""),
                                            "unit_price": item.get("unit_price", ""),
                                            "amount": item.get("amount", ""),
                                            "remark": item.get("remark", ""),
                                            "data_source": f"LINEæ³¨æ–‡_{order['timestamp']}"
                                        }
                                        records.append(record)
                                    
                                    # è§£æçµæœã‚’ä¿å­˜
                                    success, message = save_parsed_line_order_data(order['timestamp'], parsed_data)
                                    if not success:
                                        st.error(f"è§£æçµæœã®ä¿å­˜ã«å¤±æ•—: {message}")
                                    
                                    st.success("LINEæ³¨æ–‡ã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                                    st.rerun()
                                    
                            except Exception as e:
                                st.error(f"LINEæ³¨æ–‡è§£æã‚¨ãƒ©ãƒ¼: {e}")
                        
                        # å‰Šé™¤ãƒœã‚¿ãƒ³
                        if st.button(f"å‰Šé™¤", key=f"delete_{order['timestamp']}"):
                            # æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
                            orders_file = os.path.join(LINE_ORDERS_DIR, "orders.json")
                            with open(orders_file, "r", encoding="utf-8") as f:
                                all_orders = json.load(f)
                            
                            all_orders = [o for o in all_orders if o['timestamp'] != order['timestamp']]
                            
                            with open(orders_file, "w", encoding="utf-8") as f:
                                json.dump(all_orders, f, ensure_ascii=False, indent=4)
                            
                            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤
                            if os.path.exists(image_path):
                                os.remove(image_path)
                            
                            st.success("LINEæ³¨æ–‡ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                            st.rerun()
        else:
            st.info("æœªå‡¦ç†ã®LINEæ³¨æ–‡ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.info("LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")
    
    st.subheader("æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®å‰ã«é…ç½®ï¼‰
    if 'data_edited' not in st.session_state:
        st.session_state.data_edited = False
    
    if 'processed_files' not in st.session_state:
        st.session_state.processed_files = set()
    
    if 'parsed_records' not in st.session_state:
        st.session_state.parsed_records = []
    
    # PDFç”»åƒè¡¨ç¤ºè¨­å®š
    col1, col2 = st.columns([3, 1])
    with col1:
        uploaded_files = st.file_uploader(
            label="Infomart / IPORTER / PDF ç­‰ã®æ³¨æ–‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã“ã«ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã¾ãŸã¯é¸æŠã—ã¦ãã ã•ã„",
            accept_multiple_files=True,
            type=['txt', 'csv', 'xlsx', 'pdf'],
            key="file_uploader"
        )
        # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå ´åˆã®ã¿ç·¨é›†çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        if uploaded_files:
            new_files_count = 0
            for file in uploaded_files:
                file_hash = f"{file.name}_{file.size}_{file.type}"
                if file_hash not in st.session_state.processed_files:
                    new_files_count += 1
            
            if new_files_count > 0:
                st.session_state.data_edited = False
    with col2:
        show_pdf_images = st.checkbox("PDFç”»åƒã‚’è¡¨ç¤º", value=True, help="PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ç”»åƒã‚’è¡¨ç¤ºã™ã‚‹ã‹ã©ã†ã‹ã‚’è¨­å®šã—ã¾ã™")
        
        # è§£ææ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ è§£ææ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚»ãƒƒãƒˆ", key="reset_processed_files", help="è§£ææ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™"):
            st.session_state.processed_files = set()
            st.session_state.data_edited = False
            st.session_state.parsed_records = []  # è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚‚ã‚¯ãƒªã‚¢
            st.success("è§£ææ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚")
            st.rerun()

    records = []
    debug_details = []
    
    # LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚¹ã‚³ãƒ¼ãƒ—å¤–ã§ã‚‚ä½¿ç”¨ã™ã‚‹ãŸã‚ã€ã“ã“ã§å®šç¾©ï¼‰
    line_orders = get_line_orders_for_user(username)
    processed_line_orders = [order for order in line_orders if order.get("processed", False)]
    
    # ç·¨é›†æ¸ˆã¿ã®å ´åˆã¯å†è§£æã‚’ã‚¹ã‚­ãƒƒãƒ—
    if not st.session_state.data_edited:
        # æ—¢å­˜ã®è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        records = st.session_state.parsed_records.copy()
        
        # å…¨ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºæ©Ÿèƒ½ã‚’è¿½åŠ 
        if processed_line_orders:
            st.subheader("ğŸ“± è§£ææ¸ˆã¿LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿")
            
            # çµ±è¨ˆæƒ…å ±
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("è§£ææ¸ˆã¿LINEæ³¨æ–‡", len(processed_line_orders))
            with col2:
                st.metric("é€ä¿¡è€…æ•°", len(set(order['sender_name'] for order in processed_line_orders)))
            with col3:
                st.metric("æœ€æ–°æ›´æ–°", max(order['order_date'] for order in processed_line_orders) if processed_line_orders else "ãªã—")
            
            # è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°è¡¨ç¤º
            with st.expander("ğŸ“‹ è§£ææ¸ˆã¿LINEæ³¨æ–‡è©³ç´°", expanded=False):
                for i, order in enumerate(processed_line_orders):
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        st.write(f"**{i+1}. {order['sender_name']} - {order['order_date']}**")
                        st.write(f"å—ä¿¡æ—¥æ™‚: {order['timestamp']}")
                        if order.get('message_text'):
                            st.write(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {order['message_text']}")
                    
                    with col2:
                        # ç”»åƒè¡¨ç¤º
                        image_path = os.path.join(LINE_ORDERS_DIR, order['image_filename'])
                        if os.path.exists(image_path):
                            st.image(image_path, caption="LINEæ³¨æ–‡ç”»åƒ", width=200)
                    
                    st.markdown("---")
        
        # LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’recordsã«è¿½åŠ ï¼ˆã¾ã è¿½åŠ ã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ï¼‰
        existing_line_sources = {record.get("data_source", "") for record in records}
        for order in processed_line_orders:
            line_source = f"LINEæ³¨æ–‡_{order['timestamp']}"
            if line_source not in existing_line_sources:
                # å‡¦ç†æ¸ˆã¿ã®LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’recordsã«è¿½åŠ 
                st.info(f"å‡¦ç†æ¸ˆã¿LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿: {order['sender_name']} - {order['order_date']}")
                
                # ä¿å­˜ã•ã‚ŒãŸè§£æçµæœã‚’å–å¾—
                parsed_data = order.get('parsed_data')
                if parsed_data:
                    # è§£æçµæœã‹ã‚‰å•†å“æƒ…å ±ã‚’å–å¾—
                    delivery_date = parsed_data.get("delivery_date", order['order_date'])
                    items = parsed_data.get("items", [])
                    
                    for item in items:
                        record = {
                            "order_id": f"LINE_{order['timestamp']}",
                            "order_date": order['order_date'],
                            "delivery_date": delivery_date,
                            "partner_name": parsed_data.get("partner_name", order['sender_name']),
                            "product_code": item.get("product_code", ""),
                            "product_name": item.get("product_name", ""),
                            "quantity": item.get("quantity", ""),
                            "unit": item.get("unit", ""),
                            "unit_price": item.get("unit_price", ""),
                            "amount": item.get("amount", ""),
                            "remark": item.get("remark", ""),
                            "data_source": line_source
                        }
                        records.append(record)
                else:
                    # è§£æçµæœãŒãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                    record = {
                        "order_id": f"LINE_{order['timestamp']}",
                        "order_date": order['order_date'],
                        "delivery_date": order['order_date'],
                        "partner_name": order['sender_name'],
                        "product_code": "",
                        "product_name": "LINEæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ï¼ˆè§£æçµæœãªã—ï¼‰",
                        "quantity": "",
                        "unit": "",
                        "unit_price": "",
                        "amount": "",
                        "remark": f"LINEæ³¨æ–‡ - {order['timestamp']}",
                        "data_source": line_source
                    }
                    records.append(record)
        
        if uploaded_files:
            # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’å‡¦ç†
            new_files = []
            for file in uploaded_files:
                file_hash = f"{file.name}_{file.size}_{file.type}"
                if file_hash not in st.session_state.processed_files:
                    new_files.append(file)
                    st.session_state.processed_files.add(file_hash)
            
            if new_files:
                st.info(f"æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ« {len(new_files)} ä»¶ã‚’è§£æã—ã¾ã™")
                
                for file in new_files:
                    filename = file.name
                    content = file.read()

                    if filename.lower().endswith((".txt", ".csv")):
                        filetype, detected_enc, debug_log = detect_csv_type(content)
                        debug_details.append(f"ã€{filename}ã€‘\n" + "\n".join(debug_log))
                        file_like = io.BytesIO(content)
                        if filetype == 'infomart':
                            records += parse_infomart(file_like, filename)
                        elif filetype == 'iporter':
                            records += parse_iporter(file_like, filename)
                        else:
                            st.warning(f"{filename} ã¯æœªå¯¾å¿œã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã™")

                    elif filename.lower().endswith(".xlsx"):
                        try:
                            df_excel = pd.read_excel(io.BytesIO(content), sheet_name=0, header=None)
                            if df_excel.shape[0] > 5 and str(df_excel.iloc[4, 1]).strip() == "ä¼ç¥¨ç•ªå·":
                                file_like = io.BytesIO(content)
                                try:
                                    mitsubishi_records = parse_mitsubishi(file_like, filename)
                                    records += mitsubishi_records
                                    st.success(f"{filename} ã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸ")
                                except Exception as parse_error:
                                    st.error(f"{filename} ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {parse_error}")
                                    # ãƒ­ã‚°ã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—
                                    import logging
                                    logger = logging.getLogger('parser_mitsubishi')
                                    if logger.handlers:
                                        for handler in logger.handlers:
                                            if hasattr(handler, 'baseFilename'):
                                                st.info(f"è©³ç´°ãƒ­ã‚°: {handler.baseFilename}")
                            else:
                                st.warning(f"{filename} ã¯æœªå¯¾å¿œã®Excelãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã™")
                        except Exception as e:
                            st.error(f"{filename} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                    
                    elif filename.lower().endswith(".pdf"):
                        # PDFç”»åƒã®æŠ½å‡ºã¨è¡¨ç¤º
                        if show_pdf_images:
                            pdf_images = extract_pdf_images(content)
                            if pdf_images:
                                display_pdf_images(pdf_images, filename)
                        
                        # PDFè§£æã®å®Ÿè¡Œ
                        try:
                            with st.spinner(f"{filename} ã‚’è§£æä¸­..."):
                                # APIã‚­ãƒ¼ã®äº‹å‰ç¢ºèª
                                try:
                                    from config import get_openai_api_key
                                    api_key = get_openai_api_key()
                                    if not api_key:
                                        st.error("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                                        continue
                                except Exception as api_error:
                                    st.error(f"APIã‚­ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {api_error}")
                                    continue
                                
                                pdf_records = parse_pdf_handwritten(content, filename)
                                records += pdf_records
                                # å•†å“æƒ…å ±ã®æŠ½å‡ºçŠ¶æ³ã‚’ç¢ºèª
                                if pdf_records and pdf_records[0].get('product_name') == "å•†å“æƒ…å ±ãªã—":
                                    st.warning("å•†å“æƒ…å ±ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹æ›¸ãæ–‡å­—ã®èªè­˜ç²¾åº¦ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                            st.success(f"{filename} ã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸ")
                        except Exception as e:
                            st.error(f"{filename} ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                            st.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {str(e)}")
                            # æœ¬ç•ªç’°å¢ƒã§ã®è¿½åŠ æƒ…å ±
                            if is_production():
                                st.info("æœ¬ç•ªç’°å¢ƒã§ã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:")
                                st.info("1. Render Secrets Filesã§OPENAI_API_KEYãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª")
                                st.info("2. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¦ç’°å¢ƒå¤‰æ•°ã‚’åæ˜ ")
                                st.info("3. Renderã®ãƒ­ã‚°ã§è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ç¢ºèª")
            else:
                st.info("ğŸ“ ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«è§£ææ¸ˆã¿ã§ã™ã€‚æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        
        # è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
        st.session_state.parsed_records = records
    else:
        # ç·¨é›†æ¸ˆã¿ã®å ´åˆã¯æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
        st.info("ğŸ“ ãƒ‡ãƒ¼ã‚¿ãŒç·¨é›†ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨å†è§£æã•ã‚Œã¾ã™ã€‚")
        if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’å†èª­ã¿è¾¼ã¿", key="reload_data"):
            st.session_state.data_edited = False
            st.rerun()
        # ç·¨é›†æ¸ˆã¿ã®å ´åˆã‚‚æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        records = st.session_state.parsed_records.copy()

    # ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼ˆç©ºã§ã‚‚è¡¨ç¤ºï¼‰
    if records:        
        df = pd.DataFrame(records)
        
        # ç©ºè¡Œé™¤å¤–ã®æ¡ä»¶ã‚’ç·©å’Œï¼ˆå•†å“åã¾ãŸã¯å‚™è€ƒã«å€¤ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤ºï¼‰
        if not df.empty:
            # å•†å“åã¾ãŸã¯å‚™è€ƒã«å€¤ãŒã‚ã‚‹è¡Œã®ã¿ã‚’ä¿æŒ
            df = df[df['product_name'].notna() | df['remark'].notna()]
        
        if not df.empty:
            columns = [
                "order_id", "order_date", "delivery_date", "partner_name",
                "product_code", "product_name", "quantity", "unit", "unit_price", "amount", "remark", "data_source"
            ]
            df = df.reindex(columns=columns)
            df.columns = ["ä¼ç¥¨ç•ªå·", "ç™ºæ³¨æ—¥", "ç´å“æ—¥", "å–å¼•å…ˆå", "å•†å“ã‚³ãƒ¼ãƒ‰", "å•†å“å", "æ•°é‡", "å˜ä½", "å˜ä¾¡", "é‡‘é¡", "å‚™è€ƒ", "ãƒ‡ãƒ¼ã‚¿å…ƒ"]

            edited_df = st.data_editor(
                df,
                use_container_width=True,
                num_rows="dynamic",
                key="editor",
                hide_index=True,
                on_change=lambda: setattr(st.session_state, 'data_edited', True)
            )
        else:
            st.warning("è¡¨ç¤ºå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å•†å“æƒ…å ±ã®æŠ½å‡ºã«å¤±æ•—ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

        for col in ["ç™ºæ³¨æ—¥", "ç´å“æ—¥"]:
            edited_df[col] = pd.to_datetime(edited_df[col], errors="coerce").dt.strftime("%Y/%m/%d")

        edited_df["æ•°é‡"] = pd.to_numeric(edited_df["æ•°é‡"], errors="coerce").fillna(0)

        df_sorted = edited_df.sort_values(
            by=["å•†å“å", "ç´å“æ—¥", "ç™ºæ³¨æ—¥"], na_position="last"
        )

        df_agg = (
            df_sorted
            .groupby(["å•†å“å", "å‚™è€ƒ", "å˜ä½"], dropna=False, as_index=False)
            .agg({"æ•°é‡": "sum"})
        )
        df_agg = df_agg[["å•†å“å", "å‚™è€ƒ", "æ•°é‡", "å˜ä½"]]
        df_agg = df_agg.sort_values(by=["å•†å“å"])
        output = io.BytesIO()
        jst = pytz.timezone("Asia/Tokyo")
        now_str = datetime.now(jst).strftime("%y%m%d_%H%M")

        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            workbook = writer.book
            header_format = workbook.add_format({'bold': False, 'border': 0})

            # â–¼ æ³¨æ–‡ä¸€è¦§ã‚·ãƒ¼ãƒˆ
            sheet1 = "æ³¨æ–‡ä¸€è¦§"
            edited_df.to_excel(writer, index=False, sheet_name=sheet1, startrow=1, header=False)
            worksheet1 = writer.sheets[sheet1]
            for col_num, value in enumerate(edited_df.columns.values):
                worksheet1.write(0, col_num, value, header_format)

            # â–¼ æ³¨æ–‡ä¸€è¦§(å±¤åˆ¥çµæœ)ã‚·ãƒ¼ãƒˆ
            sheet2 = "æ³¨æ–‡ä¸€è¦§(å±¤åˆ¥çµæœ)"
            df_sorted.to_excel(writer, index=False, sheet_name=sheet2, startrow=1, header=False)
            worksheet2 = writer.sheets[sheet2]
            for col_num, value in enumerate(df_sorted.columns.values):
                worksheet2.write(0, col_num, value, header_format)

            # â–¼ é›†è¨ˆçµæœã‚·ãƒ¼ãƒˆ
            sheet3 = "é›†è¨ˆçµæœ"
            df_agg.to_excel(writer, index=False, sheet_name=sheet3, startrow=1, header=False)
            worksheet3 = writer.sheets[sheet3]
            for col_num, value in enumerate(df_agg.columns.values):
                worksheet3.write(0, col_num, value, header_format)

        output.seek(0)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã¨å‰Šé™¤ãƒœã‚¿ãƒ³ã‚’æ¨ªã«ä¸¦ã¹ã‚‹
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.download_button(
                label="Excelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=output,
                file_name=f"{now_str}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        
        with col2:
            if processed_line_orders:  # å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿å‰Šé™¤ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                if st.button("ğŸ—‘ï¸ å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿å‰Šé™¤", type="secondary"):
                    success, message = delete_processed_line_orders()
                    if success:
                        st.success(message)
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚‚ã‚¯ãƒªã‚¢
                        st.session_state.parsed_records = []
                        st.rerun()
                    else:
                        st.error(message)
    else:
        st.info("æ³¨æ–‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

elif st.session_state.get("authentication_status") is False:
    st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
elif st.session_state.get("authentication_status") is None:
    st.warning("ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# --- SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç† ---
def init_database():
    """SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹"""
    import sqlite3
    import os
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    db_path = '/tmp/users.db' if os.getenv('RENDER') else 'users.db'
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS users (
            email TEXT PRIMARY KEY,
            name TEXT NOT NULL,
            company TEXT NOT NULL,
            password_hash TEXT NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    conn.commit()
    conn.close()
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†: {db_path}")

def add_user_to_db(email, name, company, password_hash):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¿½åŠ ã™ã‚‹"""
    import sqlite3
    import os
    
    db_path = '/tmp/users.db' if os.getenv('RENDER') else 'users.db'
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO users (email, name, company, password_hash)
            VALUES (?, ?, ?, ?)
        ''', (email, name, company, password_hash))
        
        conn.commit()
        conn.close()
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ æˆåŠŸï¼ˆDBï¼‰: {email}")
        return True
    except sqlite3.IntegrityError:
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ {email} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
        return False
    except Exception as e:
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def load_users_from_db():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’èª­ã¿è¾¼ã‚€"""
    import sqlite3
    import os
    
    db_path = '/tmp/users.db' if os.getenv('RENDER') else 'users.db'
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT email, name, company, password_hash FROM users')
        users = cursor.fetchall()
        
        conn.close()
        
        # streamlit-authenticatorå½¢å¼ã«å¤‰æ›
        dynamic_users = {"users": {}}
        for email, name, company, password_hash in users:
            dynamic_users["users"][email] = {
                "email": email,
                "name": name,
                "company": company,
                "password": password_hash
            }
        
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã¿: {len(users)} ãƒ¦ãƒ¼ã‚¶ãƒ¼")
        return dynamic_users
    except Exception as e:
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return {"users": {}}

def check_user_exists_in_db(email):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å­˜åœ¨ã‚’ç¢ºèªã™ã‚‹"""
    import sqlite3
    import os
    
    db_path = '/tmp/users.db' if os.getenv('RENDER') else 'users.db'
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT email FROM users WHERE email = ?', (email,))
        result = cursor.fetchone()
        
        conn.close()
        return result is not None
    except Exception as e:
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return False
